{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os,random\n",
    "import numpy as np\n",
    "\n",
    "def buildSmallerTrainData(xTrain, y_train, size):\n",
    "    X = []\n",
    "    y = []\n",
    "    seen = []\n",
    "    while len(seen) < size / 2:\n",
    "        rand = random.randrange(0,len(xTrain))\n",
    "        if rand not in seen and y_train[rand] == 0:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "    seen = []      \n",
    "    while len(seen) < size / 2:\n",
    "        rand = random.randrange(0,len(xTrain))\n",
    "        if rand not in seen and y_train[rand] == 1:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def buildSmallerTestingData(xTrain, y_train, size, interval):\n",
    "    X = []\n",
    "    y = []\n",
    "    seen = []\n",
    "    rand = interval\n",
    "    while len(seen) < size / 2:\n",
    "        if rand not in seen and y_train[rand] == 0:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "        rand += 1\n",
    "    rand = interval\n",
    "    seen = []      \n",
    "    while len(seen) < size / 2:\n",
    "        if rand not in seen and y_train[rand] == 1:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "        rand += 1\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def readFromFile(path):\n",
    "    with open(path, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        return content\n",
    "\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def convert_stringArrays_to_floatArray(array):\n",
    "    intArray = []\n",
    "\n",
    "    for k in array:\n",
    "        if isfloat(k):\n",
    "            intArray.append(float(k))\n",
    "    return intArray\n",
    "\n",
    "\n",
    "def buil_db(array, value):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    n = len(array)\n",
    "    for i in range(0, n):\n",
    "        data_X.append(array[i])\n",
    "        data_Y.append(value)\n",
    "\n",
    "    return data_X, data_Y\n",
    "\n",
    "\n",
    "def readpktHistDirectFromFile(path):\n",
    "    X_data = []\n",
    "    files = os.listdir(path)\n",
    "    for f in files:\n",
    "        hist = convert_stringArrays_to_floatArray(readFromFile(path + f).split(\" \"))\n",
    "        all_pkt =sum(hist)\n",
    "        \n",
    "        X_data.append(np.array(hist))\n",
    "  \n",
    "    return X_data\n",
    "\n",
    "\n",
    "def readDataset(value,path):\n",
    "    x_train, y_train = [], []\n",
    "    dataset = readpktHistDirectFromFile(path=path)\n",
    "    data_x, data_y = buil_db(dataset, value)\n",
    "    x_train.extend(data_x)\n",
    "    y_train.extend(data_y)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "def read_train_test():\n",
    "    trainin_dataset_X = []\n",
    "    trainin_dataset_y = []\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "    names = ['caida','httpMultipleTab/4/all', 'httpMultipleTab/2/all', 'httpMultipleTab/3/all', 'httpMultipleTab/1/all',\n",
    "             \n",
    "             'noisyBitMultipleTab/4/all', 'noisyBitMultipleTab/2/all', 'noisyBitMultipleTab/3/all',\n",
    "             'noisyBitMultipleTab/1/all', 'bitcoinCaidaNoise', 'bitcoin']\n",
    "  \n",
    "\n",
    "    labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "    i = 0\n",
    "    for n in names:\n",
    "\n",
    "        x_temp,y_temp = readDataset(path='/home/fatemeh/jan 19/hist/train/' + n + \"/\"\n",
    "                                               ,value=labels[i])\n",
    "        trainin_dataset_X.extend(x_temp)\n",
    "        trainin_dataset_y.extend(y_temp)\n",
    "\n",
    "        x_temp2, y_temp2 = readDataset(path='/home/fatemeh/jan 19/hist/test/' + n + \"/\"\n",
    "                                              ,value=labels[i] )\n",
    "        print(\"read data: \",n)\n",
    "       \n",
    "        X_test.extend(x_temp2)\n",
    "        y_test.extend(y_temp2)\n",
    "        i += 1\n",
    "    \n",
    " \n",
    "    return (trainin_dataset_X,trainin_dataset_y),(X_test,y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data:  caida\n",
      "read data:  httpMultipleTab/4/all\n",
      "read data:  httpMultipleTab/2/all\n",
      "read data:  httpMultipleTab/3/all\n",
      "read data:  httpMultipleTab/1/all\n",
      "read data:  noisyBitMultipleTab/4/all\n",
      "read data:  noisyBitMultipleTab/2/all\n",
      "read data:  noisyBitMultipleTab/3/all\n",
      "read data:  noisyBitMultipleTab/1/all\n",
      "read data:  bitcoinCaidaNoise\n",
      "read data:  bitcoin\n",
      "5000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 487.9320032596588\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n",
      "batch_ size 100 number of training: 5000 Accuracy:  0.9018\n",
      "0.0024 0.806\n",
      "10000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 1032.3247485160828\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n",
      "batch_ size 100 number of training: 10000 Accuracy:  0.8928\n",
      "0.0028 0.7884\n",
      "15000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 1566.5428063869476\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ size 100 number of training: 15000 Accuracy:  0.8698\n",
      "0.0028 0.7424\n",
      "20000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 2037.589756011963\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n",
      "batch_ size 100 number of training: 20000 Accuracy:  0.9504\n",
      "0.0016 0.9024\n",
      "25000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 2556.0822184085846\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_13 (Conv1D)           (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n",
      "batch_ size 100 number of training: 25000 Accuracy:  0.8888\n",
      "0.0032 0.7808\n",
      "30000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 3052.7859411239624\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_16 (Conv1D)           (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ size 100 number of training: 30000 Accuracy:  0.915\n",
      "0.0036 0.8336\n",
      "35000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 3529.27294921875\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_19 (Conv1D)           (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_28 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n",
      "batch_ size 100 number of training: 35000 Accuracy:  0.94\n",
      "0.0028 0.8828\n",
      "40000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 4064.4424889087677\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_22 (Conv1D)           (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_29 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_29 (Dropout)         (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_30 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_30 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_31 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_32 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n",
      "batch_ size 100 number of training: 40000 Accuracy:  0.9238\n",
      "0.0032 0.8508\n",
      "50000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 4990.218192100525\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_33 (Dropout)         (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_ size 100 number of training: 50000 Accuracy:  0.9028\n",
      "0.0048 0.8104\n",
      "100000\n",
      "finished reading the training data\n",
      "finished fiting\n",
      "Time it took in seconds 9833.94884800911\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 1, 512)            776192    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 1, 512)            2048      \n",
      "_________________________________________________________________\n",
      "dropout_37 (Dropout)         (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 1, 128)            65664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 1, 128)            512       \n",
      "_________________________________________________________________\n",
      "dropout_38 (Dropout)         (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 1, 64)             8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 1, 64)             256       \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 1, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 150)               9750      \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 150)               600       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1)                 151       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 863,429\n",
      "Trainable params: 861,721\n",
      "Non-trainable params: 1,708\n",
      "_________________________________________________________________\n",
      "None\n",
      "batch_ size 100 number of training: 100000 Accuracy:  0.899\n",
      "0.0008 0.7988\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Flatten, BatchNormalization,Dropout,Conv1D,MaxPooling1D,Dropout\n",
    "from keras.layers.core import Activation\n",
    "from keras.utils import plot_model\n",
    "import time\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = read_train_test()\n",
    "XTrainCopy, yTrainCopy = np.array(x_train), np.array(y_train)\n",
    "xTestCopy, yTestCopy = np.array(x_test), np.array(y_test) \n",
    "def get_NN_model():\n",
    "    model = Sequential()\n",
    "    # model.add(Flatten(input_shape=(1, 1515)))\n",
    "    model.add(Conv1D(512, 1, activation='relu',input_shape=(1, 1515)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "\n",
    "    model.add(Conv1D(128, 1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "\n",
    "    model.add(Conv1D(64, 1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(150))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def write_to_json(model, number):\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(\"/home/fatemeh/jan 19/hist/models/model_hist_\" + str(number) + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"/home/fatemeh/jan 19/hist/models/model_hist_\" + str(number) + \".h5\")\n",
    "\n",
    "\n",
    "sizes=[5000]#, 10000, 15000, 20000, 25000, 30000, 35000, 40000, 50000, 100000]\n",
    "for size in sizes:\n",
    "    print(size)\n",
    "    X, y = buildSmallerTrainData(XTrainCopy, yTrainCopy, size = size)\n",
    "    print(\"finished reading the training data\")\n",
    "    X = np.expand_dims(X, axis=1)\n",
    "    model = get_NN_model()\n",
    "    start = time.time()\n",
    "    model.fit(X, y, epochs = 800, batch_size=128, verbose=0)#, batch_size=64)\n",
    "    print(\"finished fiting\")\n",
    "    end = time.time()\n",
    "    print(\"Time it took in seconds\", end - start)\n",
    "\n",
    "    write_to_json(model, number=size)\n",
    "    print(model.summary())\n",
    "    xT ,yT = buildSmallerTrainData(xTestCopy, yTestCopy, size = 5000)#buildSmallerTestingData(xTrain=xTestCopy, y_train=yTestCopy, size=5000,interval=p*5000)#xTestCopy, yTestCopy#\n",
    "    xT = np.expand_dims(xT, axis=1)\n",
    "    y_pred = model.predict(xT)\n",
    "\n",
    "    accur = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    nAll_one = sum(yT)\n",
    "    nZeros = len(yT) - nAll_one\n",
    "    for v in range(len(y_pred)):\n",
    "        if y_pred[v] >= 0.5 and yT[v] == 1:\n",
    "             accur += 1\n",
    "             true_pos += 1\n",
    "        if y_pred[v] < 0.5 and yT[v] == 0:\n",
    "             accur += 1\n",
    "\n",
    "        if y_pred[v] >= 0.5 and yT[v] == 0:\n",
    "            false_pos += 1\n",
    "\n",
    "\n",
    "    accur = accur/float(len(y_pred))\n",
    "    print( \"batch_ size\", 100,\"number of training:\",size,\"Accuracy: \", accur)\n",
    "    print(false_pos/float(nZeros),true_pos/float(nAll_one))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5000/5000 [==============================] - 4s 790us/step - loss: 1.3810e-06 - acc: 1.0000\n",
      "Epoch 2/100\n",
      "5000/5000 [==============================] - 1s 143us/step - loss: 2.5469e-04 - acc: 0.9998\n",
      "Epoch 3/100\n",
      "5000/5000 [==============================] - 1s 144us/step - loss: 1.9653e-06 - acc: 1.0000\n",
      "Epoch 4/100\n",
      "5000/5000 [==============================] - 1s 157us/step - loss: 6.0457e-06 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "5000/5000 [==============================] - 1s 153us/step - loss: 5.5074e-06 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "5000/5000 [==============================] - 1s 146us/step - loss: 1.5198e-05 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 9.4316e-06 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 7.9512e-05 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "5000/5000 [==============================] - 1s 156us/step - loss: 7.1703e-06 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "5000/5000 [==============================] - 1s 147us/step - loss: 8.5815e-07 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "5000/5000 [==============================] - 1s 158us/step - loss: 1.3157e-04 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "5000/5000 [==============================] - 1s 174us/step - loss: 1.4597e-05 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "5000/5000 [==============================] - 1s 168us/step - loss: 1.7931e-06 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "5000/5000 [==============================] - 1s 163us/step - loss: 0.0048 - acc: 0.9996\n",
      "Epoch 15/100\n",
      "5000/5000 [==============================] - 1s 161us/step - loss: 1.0644e-04 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "5000/5000 [==============================] - 1s 159us/step - loss: 5.9237e-04 - acc: 0.9998\n",
      "Epoch 17/100\n",
      "5000/5000 [==============================] - 1s 165us/step - loss: 3.9174e-05 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "5000/5000 [==============================] - 1s 145us/step - loss: 4.9937e-05 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 4.6960e-06 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 8.4619e-06 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "5000/5000 [==============================] - 1s 149us/step - loss: 2.0680e-05 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "5000/5000 [==============================] - 1s 143us/step - loss: 1.4538e-05 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "5000/5000 [==============================] - 1s 143us/step - loss: 1.7939e-05 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "5000/5000 [==============================] - 1s 145us/step - loss: 6.0583e-06 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "5000/5000 [==============================] - 1s 147us/step - loss: 2.7178e-04 - acc: 0.9998\n",
      "Epoch 26/100\n",
      "5000/5000 [==============================] - 1s 147us/step - loss: 1.5062e-05 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 2.0485e-06 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "5000/5000 [==============================] - 1s 145us/step - loss: 6.8510e-06 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 30/100\n",
      "5000/5000 [==============================] - 1s 143us/step - loss: 6.2564e-05 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "5000/5000 [==============================] - 1s 141us/step - loss: 2.7674e-05 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "5000/5000 [==============================] - 1s 141us/step - loss: 0.0119 - acc: 0.9990\n",
      "Epoch 33/100\n",
      "5000/5000 [==============================] - 1s 141us/step - loss: 5.1599e-05 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 1.5785e-04 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "5000/5000 [==============================] - 1s 143us/step - loss: 9.7966e-06 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "5000/5000 [==============================] - 1s 142us/step - loss: 3.0373e-05 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "5000/5000 [==============================] - 1s 142us/step - loss: 4.1188e-05 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "5000/5000 [==============================] - 1s 145us/step - loss: 9.5231e-04 - acc: 0.9998\n",
      "Epoch 39/100\n",
      "5000/5000 [==============================] - 1s 144us/step - loss: 4.0400e-04 - acc: 0.9998\n",
      "Epoch 40/100\n",
      "5000/5000 [==============================] - 1s 142us/step - loss: 2.5869e-05 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "5000/5000 [==============================] - 1s 141us/step - loss: 6.7228e-04 - acc: 0.9998\n",
      "Epoch 42/100\n",
      "5000/5000 [==============================] - 1s 151us/step - loss: 2.2346e-05 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "5000/5000 [==============================] - 1s 142us/step - loss: 0.0023 - acc: 0.9992\n",
      "Epoch 44/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 0.0018 - acc: 0.9998\n",
      "Epoch 45/100\n",
      "5000/5000 [==============================] - 1s 166us/step - loss: 1.5243e-04 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "5000/5000 [==============================] - 1s 164us/step - loss: 3.3072e-04 - acc: 0.9998\n",
      "Epoch 47/100\n",
      "5000/5000 [==============================] - 1s 156us/step - loss: 4.0486e-05 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "5000/5000 [==============================] - 1s 142us/step - loss: 2.1231e-04 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "5000/5000 [==============================] - 1s 139us/step - loss: 5.9613e-05 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "5000/5000 [==============================] - 1s 149us/step - loss: 4.7793e-05 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "5000/5000 [==============================] - 1s 139us/step - loss: 2.5589e-04 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "5000/5000 [==============================] - 1s 140us/step - loss: 5.1332e-05 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "5000/5000 [==============================] - 1s 141us/step - loss: 2.2455e-04 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "5000/5000 [==============================] - 1s 160us/step - loss: 5.3734e-05 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "5000/5000 [==============================] - 1s 155us/step - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 56/100\n",
      "5000/5000 [==============================] - 1s 155us/step - loss: 7.5042e-05 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "5000/5000 [==============================] - 1s 151us/step - loss: 6.8759e-05 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "5000/5000 [==============================] - 1s 156us/step - loss: 5.9092e-05 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 8.8078e-05 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "5000/5000 [==============================] - 1s 147us/step - loss: 7.7511e-05 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "5000/5000 [==============================] - 1s 151us/step - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 62/100\n",
      "5000/5000 [==============================] - 1s 155us/step - loss: 7.6387e-05 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "5000/5000 [==============================] - 1s 152us/step - loss: 7.2272e-05 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "5000/5000 [==============================] - 1s 149us/step - loss: 4.2657e-05 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "5000/5000 [==============================] - 1s 149us/step - loss: 1.6813e-04 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "5000/5000 [==============================] - 1s 155us/step - loss: 6.6010e-04 - acc: 0.9998\n",
      "Epoch 67/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 5.8233e-05 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "5000/5000 [==============================] - 1s 151us/step - loss: 2.2259e-05 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 3.4095e-05 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "5000/5000 [==============================] - 1s 151us/step - loss: 3.3823e-05 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "5000/5000 [==============================] - 1s 147us/step - loss: 2.0211e-04 - acc: 0.9998\n",
      "Epoch 72/100\n",
      "5000/5000 [==============================] - 1s 147us/step - loss: 2.4447e-05 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "5000/5000 [==============================] - 1s 149us/step - loss: 5.1511e-05 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "5000/5000 [==============================] - 1s 155us/step - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 75/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 1.9234e-04 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "5000/5000 [==============================] - 1s 146us/step - loss: 1.7428e-04 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "5000/5000 [==============================] - 1s 153us/step - loss: 1.6628e-04 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "5000/5000 [==============================] - 1s 160us/step - loss: 1.2468e-04 - acc: 1.0000\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 1s 149us/step - loss: 1.3889e-04 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 1.0313e-04 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "5000/5000 [==============================] - 1s 147us/step - loss: 1.0544e-04 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "5000/5000 [==============================] - 1s 152us/step - loss: 8.6389e-05 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "5000/5000 [==============================] - 1s 148us/step - loss: 1.1764e-04 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 1.0528e-04 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "5000/5000 [==============================] - 1s 154us/step - loss: 7.0752e-05 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "5000/5000 [==============================] - 1s 153us/step - loss: 7.1297e-05 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 5.3983e-05 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "5000/5000 [==============================] - 1s 153us/step - loss: 4.4371e-05 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "5000/5000 [==============================] - 1s 155us/step - loss: 5.0360e-05 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "5000/5000 [==============================] - 1s 146us/step - loss: 6.2235e-05 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "5000/5000 [==============================] - 1s 151us/step - loss: 4.5803e-04 - acc: 0.9998\n",
      "Epoch 92/100\n",
      "5000/5000 [==============================] - 1s 147us/step - loss: 5.9862e-05 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "5000/5000 [==============================] - 1s 145us/step - loss: 5.8212e-05 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "5000/5000 [==============================] - 1s 157us/step - loss: 5.5412e-05 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 7.8096e-05 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "5000/5000 [==============================] - 1s 145us/step - loss: 2.9394e-05 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "5000/5000 [==============================] - 1s 155us/step - loss: 3.2818e-05 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "5000/5000 [==============================] - 1s 150us/step - loss: 4.8305e-05 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "5000/5000 [==============================] - 1s 156us/step - loss: 3.5726e-05 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "5000/5000 [==============================] - 1s 149us/step - loss: 3.6916e-05 - acc: 1.0000\n",
      "model_hist_100000.json :    0.0012 0.8033333333333333 0.8921818181818182 60000 50000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "def load_NN_model(name):\n",
    "    \n",
    "    json_file = open(\"/home/fatemeh/jan 19/hist/models/\"+name , 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = model_from_json(loaded_model_json)\n",
    "    model.load_weights(\"/home/fatemeh/jan 19/hist/models/\"+name[:-5] + \".h5\")\n",
    "    return model\n",
    "\n",
    "models=os.listdir('/home/fatemeh/jan 19/hist/models/')\n",
    "for mod in models[0:1]:\n",
    "    if 'model_hist' in mod and 'json'in mod:\n",
    "        \n",
    "        model= load_NN_model(name=mod)  \n",
    "        X, y = buildSmallerTrainData(XTrainCopy, yTrainCopy, size = 5000)\n",
    "        X = np.expand_dims(X, axis=1)\n",
    "        model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "        model.fit(X, y, epochs = 100, batch_size=128, verbose=1)\n",
    "#         model = load_model(\"/home/fatemeh/jan 19/hist/models/\"+mod[:-5] + \".h5\")\n",
    "        #model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        xT ,yT = xTestCopy, yTestCopy#buildSmallerTrainData(xTestCopy, yTestCopy, size = 60000)#buildSmallerTestingData(xTrain=xTestCopy, y_train=yTestCopy, size=5000,interval=p*5000)#xTestCopy, yTestCopy#\n",
    "        xT = np.expand_dims(xT, axis=1)\n",
    "        y_pred = model.predict(xT)\n",
    "        accur = 0\n",
    "        true_pos = 0\n",
    "        false_pos = 0\n",
    "        number_of_all_one = sum(yT)\n",
    "        nZeros = len(yT) - number_of_all_one\n",
    "        for v in range(len(y_pred)):\n",
    "            if y_pred[v] >= 0.5 and yT[v] == 1:\n",
    "                 accur += 1\n",
    "                 true_pos += 1\n",
    "            if y_pred[v] < 0.5 and yT[v] == 0:\n",
    "                 accur += 1\n",
    "\n",
    "            if y_pred[v] >= 0.5 and yT[v] == 0:\n",
    "                false_pos += 1\n",
    "\n",
    "\n",
    "        accur = accur/float(len(y_pred))\n",
    "        print(mod, \":   \", false_pos/float(nZeros),true_pos/float(number_of_all_one),\n",
    "              accur, number_of_all_one,nZeros)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
