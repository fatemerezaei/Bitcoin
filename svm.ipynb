{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def readFromFile(path):\n",
    "    with open(path, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        return content  # .split(\" \")\n",
    "\n",
    "def writeToFile(array, path, delimiter):\n",
    "    target = open(path, 'w')\n",
    "\n",
    "    for line in array:\n",
    "        target.write(str(line) + delimiter)\n",
    "    target.close()\n",
    "\n",
    "def createHistFromPkst(pkts):\n",
    "    numberOfPkts = 0\n",
    "\n",
    "    hist = [0] * 1515\n",
    "    largerThanMTU = 0\n",
    "    for i in range(0, len(pkts)):\n",
    "        if pkts[i] not in [0, 40, 52]:\n",
    "            if pkts[i] < len(hist):\n",
    "                hist[int(pkts[i])] += 1\n",
    "                numberOfPkts += 1\n",
    "            else:\n",
    "                largerThanMTU += 1\n",
    "    for h in range(0, len(hist)):\n",
    "        hist[h] /= float(numberOfPkts)\n",
    "    if largerThanMTU / float((largerThanMTU + numberOfPkts)) < 0.05:\n",
    "        return hist\n",
    "    else:\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "def plot_features(X, y, labels, nTrain):\n",
    "    # from sklearn.datasets.samples_generator import make_blobs\n",
    "    # X, y = make_blobs(n_samples=50, centers=3, n_features=5, random_state=0)\n",
    "    pca = sklearnPCA(n_components=2)  # 2-dimensional PCA\n",
    "    transformed = pd.DataFrame(pca.fit_transform(X))\n",
    "    XPCA = pca.fit_transform(X)\n",
    "\n",
    "    colors = {0: \"red\", 1: \"blue\", 2: \"yellow\", 3: \"pink\", 4: \"lightgreen\"}\n",
    "    for k in range(len(labels)):\n",
    "        plt.scatter(transformed[y == k][0], transformed[y == k][1], label=labels[k], c=colors[k], edgecolors=colors[k])\n",
    "        '''plt.scatter(XPCA[:, 0][nTrain * k:nTrain * (1 + k)],\n",
    "               XPCA[:, 1][nTrain * k:nTrain * (1 + k)], label=labels[k], c=colors[k],\n",
    "              edgecolors=colors[k])'''\n",
    "        # print XPCA[:, 0][nTrain * k:nTrain * (1 + k)]\n",
    "        # print XPCA[:, 1][nTrain * k:nTrain * (1 + k)]\n",
    "        # print XPCA[:, 0][nTrain * k:nTrain * (1 + k)]\n",
    "    # plt.xlim(-1, 1)\n",
    "    # plt.ylim(-1, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def computerAccuracy(predict_array_bitcoin_test, predict_array_other_test, trueSet):\n",
    "    accuracy = 0\n",
    "\n",
    "    for k in range(0, len(predict_array_other_test)):\n",
    "        if predict_array_other_test[k] not in trueSet:\n",
    "            accuracy += 1\n",
    "    for k in range(0, len(predict_array_bitcoin_test)):\n",
    "        if predict_array_bitcoin_test[k] in trueSet:  # ,2]:\n",
    "            accuracy += 1\n",
    "\n",
    "    return accuracy / float(len(predict_array_other_test) + len(predict_array_bitcoin_test))\n",
    "\n",
    "\n",
    "def computeRecall(predict_array_bitcoin_test, trueSet):\n",
    "    truePos = 0\n",
    "    for k in range(0, len(predict_array_bitcoin_test)):\n",
    "        if predict_array_bitcoin_test[k] in trueSet:\n",
    "            truePos += 1\n",
    "    return truePos / float(len(predict_array_bitcoin_test))\n",
    "\n",
    "\n",
    "def computePrecision(predict_array_other_test, predict_array_bitcoin_test, trueSet):\n",
    "    truePostive = 0\n",
    "    falsePositive = 0\n",
    "    for k in predict_array_bitcoin_test:\n",
    "        if k in trueSet:\n",
    "            truePostive += 1\n",
    "\n",
    "    for k in predict_array_other_test:\n",
    "        if k in trueSet:\n",
    "            falsePositive += 1\n",
    "    precsion = 0\n",
    "    if float(falsePositive + truePostive) != 0:\n",
    "        precsion = truePostive / float(falsePositive + truePostive)\n",
    "    # print truePostive, falsePositive, \"true positive, false positive\"\n",
    "    return precsion, (truePostive, falsePositive)\n",
    "\n",
    "# /home/fatemeh/dataset/Data/SimpleUser/bittorent_noise/vanilla/noise\n",
    "\n",
    "def buil_db(array, value):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    n = len(array)\n",
    "    for i in range(0, n):\n",
    "        data_X.append(array[i])\n",
    "        data_Y.append(value)\n",
    "\n",
    "    return data_X, data_Y\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def convert_stringArrays_to_floatArray(array):\n",
    "    intArray = []\n",
    "\n",
    "    for k in array:\n",
    "        if isfloat(k):\n",
    "            intArray.append(float(k))\n",
    "    return intArray\n",
    "\n",
    "\n",
    "def get_sizeHist_array_1sec(array_hist):\n",
    "    array_hist[40] = 0\n",
    "    array_hist[52] = 0\n",
    "    array_hist[54] = 0\n",
    "    array_hist[0] = 0\n",
    "    all_pkt = sum(array_hist)\n",
    "\n",
    "    for i in range(0, len(array_hist)):\n",
    "        array_hist[i] /= float(all_pkt)\n",
    "    return array_hist\n",
    "\n",
    "\n",
    "def readpktHistDirectFromFile(path, max_read):\n",
    "    X_data = []\n",
    "    files = os.listdir(path)\n",
    "    w = 0\n",
    "    for f in range(max_read):\n",
    "        try:\n",
    "            rnd = random.randrange(0, len(files))\n",
    "            hist = convert_stringArrays_to_floatArray(readFromFile(path + files[rnd]).split(\" \"))\n",
    "            # array_hist = get_sizeHist_array_1sec(array_hist=hist)\n",
    "            #\n",
    "            # if len(array_hist) != 0:\n",
    "            if sum(hist) != 0:\n",
    "                X_data.append(np.array(hist))\n",
    "        except:\n",
    "            w += 1\n",
    "    # print w\n",
    "    return X_data\n",
    "\n",
    "\n",
    "def buildSmallerTrainData(xTrain, y_train, size):\n",
    "    X = []\n",
    "    y = []\n",
    "    seen = []\n",
    "    while len(seen) < size:\n",
    "        rand = random.randrange(0, len(xTrain))\n",
    "        if rand not in seen:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def read_hist_dataset():\n",
    "    '''\n",
    "    In this function, I read the training and testing seperately. train is in histDataset2/train and test is in\n",
    "    histDataset2/test\n",
    "    previous dataset: '/home/fatemeh/Bitcoin/dec 28/histDataset2/train/' + n + \"/\"\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    trainin_dataset_X = []\n",
    "    trainin_dataset_y = []\n",
    "    bitcoin_test = []\n",
    "    other_test = []\n",
    "    names = [ 'httpMultipleTab/2/all', 'httpMultipleTab/3/all', 'httpMultipleTab/1/all',\n",
    "            \n",
    "              'noisyBitMultipleTab/2/all', 'noisyBitMultipleTab/3/all',\n",
    "             'noisyBitMultipleTab/1/all','bitcoin/all']\n",
    "\n",
    "\n",
    "    trueLablems = [1]\n",
    "    labels = [0, 0, 0, 1, 1, 1, 1, 1,1]\n",
    "\n",
    "    i = 0\n",
    "    for n in names:\n",
    "        dataset_tr = readpktHistDirectFromFile(path='/home/fatemeh/jan 19/vlm/train/' + n + \"/\"\n",
    "                                               , max_read=4000)\n",
    "        X, y = buil_db(dataset_tr, value=labels[i])\n",
    "        trainin_dataset_X.extend(X)\n",
    "        trainin_dataset_y.extend(y)\n",
    "\n",
    "        dataset_ts = readpktHistDirectFromFile(path='/home/fatemeh/jan 19/vlm/test/' + n + \"/\", max_read=500\n",
    "                                               )\n",
    "        print (n, \"####\", len(dataset_tr), len(dataset_ts))\n",
    "        if labels[i] == 0:\n",
    "            other_test.extend(dataset_ts)\n",
    "        else:\n",
    "            bitcoin_test.extend(dataset_ts)\n",
    "        i += 1\n",
    "    bitcoin_test = np.array(bitcoin_test)\n",
    "    other_test = np.array(other_test)\n",
    "    print (\"Finished reading the dataset ...\")\n",
    "    return trainin_dataset_X, trainin_dataset_y, bitcoin_test, other_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "from keras.models import model_from_json\n",
    "# load json and create model\n",
    "json_file = open('model5000caida.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model5000caida.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    "\n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "loaded_model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "httpMultipleTab/2/all #### 4000 500\n",
      "httpMultipleTab/3/all #### 4000 500\n",
      "httpMultipleTab/1/all #### 4000 500\n",
      "noisyBitMultipleTab/2/all #### 4000 500\n",
      "noisyBitMultipleTab/3/all #### 4000 500\n",
      "noisyBitMultipleTab/1/all #### 4000 500\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/fatemeh/jan 19/vlm/train/bitcoin/all/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-81420a74b423>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainin_dataset_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainin_dataset_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbitcoin_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_hist_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-44-1f2df2a4c61f>\u001b[0m in \u001b[0;36mread_hist_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         dataset_tr = readpktHistDirectFromFile(path='/home/fatemeh/jan 19/vlm/train/' + n + \"/\"\n\u001b[0;32m--> 199\u001b[0;31m                                                , max_read=4000)\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuil_db\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mtrainin_dataset_X\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-1f2df2a4c61f>\u001b[0m in \u001b[0;36mreadpktHistDirectFromFile\u001b[0;34m(path, max_read)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreadpktHistDirectFromFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mX_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_read\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/fatemeh/jan 19/vlm/train/bitcoin/all/'"
     ]
    }
   ],
   "source": [
    "trainin_dataset_X, trainin_dataset_y, bitcoin_test, other_test = read_hist_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training:  100\n",
      "0.50361 0.4733755094997042 0.87775 0.87053 0.87775\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-6b6c20f516f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mbitTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildSmallerTrainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbitcoin_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbitcoin_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0motherTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuildSmallerTrainData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mpredict_array_bitcoin_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbitTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mpredict_array_other_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0motherTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputerAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_array_bitcoin_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_array_other_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrueSet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrueLablems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    565\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m         \"\"\"\n\u001b[0;32m--> 567\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    325\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_dense_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobA_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprobB_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msvm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m             \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m             cache_size=self.cache_size)\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_sparse_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "number_of_repeat=[100, 50, 25, 10, 10,10, 10]\n",
    "sizes = [100, 500, 1000, 2000, 5000, 10000]\n",
    "trueLablems=[1]\n",
    "i=0\n",
    "for size in sizes:\n",
    "    acu_av = 0\n",
    "    prec_av = 0\n",
    "    rec_av = 0\n",
    "    tru_pos, false_pos = 0, 0\n",
    "    \n",
    "    for p in range(number_of_repeat[i]):\n",
    "        trainX, trainY = buildSmallerTrainData(trainin_dataset_X, trainin_dataset_y, size=size)\n",
    "        clf =SVC(kernel='rbf', C=1000, gamma=0.001)#SVC(kernel='linear', C=1000)\n",
    "        clf.fit(trainX, trainY)\n",
    "        bitTest, t = buildSmallerTrainData(bitcoin_test, np.zeros(len(bitcoin_test)), size=1000)\n",
    "        otherTest, t = buildSmallerTrainData(other_test, np.zeros(len(other_test)), size=1000)\n",
    "        predict_array_bitcoin_test = clf.predict(bitTest)\n",
    "        predict_array_other_test = clf.predict(otherTest)\n",
    "        accuracy = computerAccuracy(predict_array_bitcoin_test, predict_array_other_test, trueSet=trueLablems)\n",
    "        recall = computeRecall(predict_array_bitcoin_test, trueSet=trueLablems)\n",
    "\n",
    "        precision, (truePostive, falsePositive) = computePrecision(predict_array_other_test,\n",
    "                                                                   predict_array_bitcoin_test,\n",
    "                                                                   trueSet=trueLablems)\n",
    "\n",
    "        rec_av += recall\n",
    "        acu_av += accuracy\n",
    "        prec_av += precision\n",
    "        tru_pos += truePostive\n",
    "        false_pos += falsePositive\n",
    "    \n",
    "    print (\"size of training: \",size)\n",
    "    print (acu_av / float(number_of_repeat[i]), prec_av / float(number_of_repeat[i]), rec_av / float(number_of_repeat[i]), false_pos / float(\n",
    "        number_of_repeat[i] * len(otherTest)), tru_pos / float(number_of_repeat[i] * len(bitTest)))\n",
    "    i += 1\n",
    "\n",
    "'''\n",
    "We have up to 4 numbe of open tabs.\n",
    "\n",
    "size of training:  100\n",
    "0.7930399999999997 0.8458535192965987 0.7400700000000003 0.15399 0.74007\n",
    "size of training:  500\n",
    "0.87886 0.9393219281848867 0.8149200000000002 0.0572 0.81492\n",
    "size of training:  1000\n",
    "0.9078800000000001 0.9769051837530914 0.8364800000000002 0.02072 0.83648\n",
    "size of training:  2000\n",
    "0.9237 0.9885841820176993 0.8568999999999999 0.0095 0.8569\n",
    "size of training:  5000\n",
    "0.9364500000000001 0.9964006546371834 0.8761000000000001 0.0032 0.8761\n",
    "\n",
    "over tor:\n",
    "\n",
    "size of training:  100\n",
    "0.7401800000000002 0.8323586718260485 0.6138 0.13344 0.6138\n",
    "size of training:  500\n",
    "0.80372 0.8333940298183468 0.7614200000000001 0.15398 0.76142\n",
    "size of training:  1000\n",
    "0.8295800000000001 0.8487272338731685 0.8025199999999999 0.14336 0.80252\n",
    "size of training:  2000\n",
    "0.8423999999999999 0.8453020672054585 0.8385 0.1537 0.8385\n",
    "size of training:  5000\n",
    "0.85885 0.8499861857056393 0.8717 0.154 0.8717\n",
    "\n",
    "size of training:  10000\n",
    "0.86785 0.8535532475341052 0.8882 0.1525 0.8882\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
