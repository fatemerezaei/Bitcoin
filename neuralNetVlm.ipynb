{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_model_history(model_history):\n",
    "    fig, axs = plt.subplots(1,2,figsize=(15,5))\n",
    "    # summarize history for accuracy\n",
    "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
    "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
    "    axs[0].set_title('Model Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
    "    axs[0].legend(['train', 'val'], loc='best')\n",
    "    # summarize history for loss\n",
    "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
    "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
    "    axs[1].set_title('Model Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
    "    axs[1].legend(['train', 'val'], loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def convert_stringArrays_to_floatArray(array):\n",
    "    intArray = []\n",
    "\n",
    "    for k in array:\n",
    "        if isfloat(k):\n",
    "            intArray.append(float(k))\n",
    "    return intArray\n",
    "\n",
    "\n",
    "\n",
    "def readFromFile(path):\n",
    "    with open(path, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        return content\n",
    "\n",
    "\n",
    "def buil_db(array, value):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    n = len(array)\n",
    "    for i in range(0, n):\n",
    "        data_X.append(array[i])\n",
    "        data_Y.append(value)\n",
    "\n",
    "    return data_X, data_Y\n",
    "\n",
    "\n",
    "def buildSmallerTrainDataSameFalseandTrue(xTrain, y_train, size):\n",
    "    X = []\n",
    "    y = []\n",
    "    seen = []\n",
    "    while len(seen) < size / 2:\n",
    "        rand = random.randrange(0,len(xTrain))\n",
    "        if rand not in seen and y_train[rand] == 0:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "    seen = []      \n",
    "    while len(seen) < size / 2:\n",
    "        rand = random.randrange(0,len(xTrain))\n",
    "        if rand not in seen and y_train[rand] == 1:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def buildSmallerTrainData(xTrain, y_train, size):\n",
    "    X = []\n",
    "    y = []\n",
    "    seen = []\n",
    "    while len(seen) < size :\n",
    "        rand = random.randrange(0,len(xTrain))\n",
    "        if rand not in seen:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def buildSmallerTestingData(xTrain, y_train, size, interval):\n",
    "    X = []\n",
    "    y = []\n",
    "    seen = []\n",
    "    rand = interval\n",
    "    while len(seen) < size / 2:\n",
    "        if rand not in seen and y_train[rand] == 0:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "        rand += 1\n",
    "            \n",
    "    rand = interval\n",
    "    seen = []      \n",
    "    while len(seen) < size / 2:\n",
    "        if rand not in seen and y_train[rand] == 1:\n",
    "            X.append(xTrain[rand])\n",
    "            y.append(y_train[rand])\n",
    "            seen.append(rand)\n",
    "            \n",
    "        rand += 1\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def readpktHistDirectFromFile(path):\n",
    "    X_data = []\n",
    "    files = os.listdir(path)[0:5000]\n",
    "    for f in files:\n",
    "        if os.path.isfile(path + f):\n",
    "            hist = convert_stringArrays_to_floatArray(readFromFile(path + f).split(\" \"))\n",
    "            X_data.append(np.array(hist))\n",
    "  \n",
    "    return X_data\n",
    "\n",
    "def readDataset(value,path):\n",
    "    x_train, y_train = [], []\n",
    "    dataset = readpktHistDirectFromFile(path = path)\n",
    "    data_x, data_y = buil_db(dataset, value)\n",
    "    x_train.extend(data_x)\n",
    "    y_train.extend(data_y)\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "def read_train_test():\n",
    "    trainin_dataset_X = []\n",
    "    trainin_dataset_y = []\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "   \n",
    "    \n",
    "    names = ['httpMultipleTab/4', 'httpMultipleTab/2', 'httpMultipleTab/3', 'httpMultipleTab/1',\n",
    "            'caida',\n",
    "             'noisyBitMultipleTab/4', 'noisyBitMultipleTab/2', 'noisyBitMultipleTab/3',\n",
    "             'noisyBitMultipleTab/1','bitcoin','bitcoinCaida']\n",
    "    \n",
    "    trueLablems = [1]\n",
    "    labels = [0, 0, 0, 0,0, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "    i = 0\n",
    "    address = '/home/fatemeh/MyProjects/Bitcoin_Traffic_Analysis'\n",
    "    for n in names:\n",
    "\n",
    "        \n",
    "\n",
    "        x_temp,y_temp = readDataset(path=address+'/jan 19/vlm_0remove/10s_2/train/' + n + \"/\"\n",
    "                                               ,value=labels[i])\n",
    "        trainin_dataset_X.extend(x_temp)\n",
    "        trainin_dataset_y.extend(y_temp)\n",
    "\n",
    "        x_temp2, y_temp2 = readDataset(path=address+'/jan 19/vlm_0remove/10s_2/test/' + n + \"/\"\n",
    "                                              ,value=labels[i] )\n",
    "        print(\"read data: \",n, len(x_temp), len(x_temp2))\n",
    "       \n",
    "        X_test.extend(x_temp2)\n",
    "        y_test.extend(y_temp2)\n",
    "        i += 1\n",
    "    \n",
    " \n",
    "    return (trainin_dataset_X,trainin_dataset_y), (X_test,y_test)\n",
    "\n",
    "def read_train_test_2():\n",
    "    trainin_dataset_X = []\n",
    "    trainin_dataset_y = []\n",
    "    X_test=[]\n",
    "    y_test=[]\n",
    "   \n",
    "    \n",
    "    names = ['http/1', 'http/2', 'http/3', 'http/4', 'http/5',\n",
    "             'caida/1', 'caida/2', 'caida/3', 'caida/4', 'caida/5'\n",
    "             ,'bitcoin_noisy/1', 'bitcoin_noisy/2',\n",
    "             'bitcoin_noisy/3',\n",
    "             'bitcoin_noisy/4', 'bitcoin_noisy/5',\n",
    "             'bitcoin', 'bitcoin_caida/1'\n",
    "             , 'bitcoin_caida/2','bitcoin_caida/3','bitcoin_caida/4', 'bitcoin_caida/5']#caida\n",
    "#     names = ['caida/1','bitcoin_caida/1']\n",
    "    \n",
    "    trueLablems = [1]\n",
    "#     labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1]\n",
    "    i = 0\n",
    "    address = '/home/fatemeh/MyProjects/Bitcoin_Traffic_Analysis/April - 2020'\n",
    "    for n in names:\n",
    "\n",
    "        if 'bitcoin' in n:\n",
    "            label = 1\n",
    "        else:\n",
    "            label = 0\n",
    "\n",
    "        x_temp,y_temp = readDataset(path = address +'/' + n + \"/train/\", value=label)\n",
    "        trainin_dataset_X.extend(x_temp)\n",
    "        trainin_dataset_y.extend(y_temp)\n",
    "\n",
    "        x_temp2, y_temp2 = readDataset(path = address+'/' + n + \"/test/\", value=label)\n",
    "        print(\"read data: \",n, len(x_temp), len(x_temp2))\n",
    "       \n",
    "        X_test.extend(x_temp2)\n",
    "        y_test.extend(y_temp2)\n",
    "        i += 1\n",
    "    \n",
    " \n",
    "    return (trainin_dataset_X, trainin_dataset_y), (X_test,y_test)\n",
    "\n",
    "def y_pred_process(y_pred, threshold):\n",
    "    output = []\n",
    "    for y in y_pred:\n",
    "        if y >= threshold:\n",
    "            output.append(1)\n",
    "        else:\n",
    "            output.append(0)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('read data: ', 'http/1', 5000, 2000)\n",
      "('read data: ', 'http/2', 5000, 2000)\n",
      "('read data: ', 'http/3', 5000, 2000)\n",
      "('read data: ', 'http/4', 5000, 2000)\n",
      "('read data: ', 'http/5', 5000, 2000)\n",
      "('read data: ', 'caida/1', 5000, 2000)\n",
      "('read data: ', 'caida/2', 5000, 2000)\n",
      "('read data: ', 'caida/3', 5000, 2000)\n",
      "('read data: ', 'caida/4', 5000, 2000)\n",
      "('read data: ', 'caida/5', 5000, 2000)\n",
      "('read data: ', 'bitcoin_noisy/1', 5000, 2000)\n",
      "('read data: ', 'bitcoin_noisy/2', 5000, 2000)\n",
      "('read data: ', 'bitcoin_noisy/3', 5000, 2000)\n",
      "('read data: ', 'bitcoin_noisy/4', 5000, 2000)\n",
      "('read data: ', 'bitcoin_noisy/5', 5000, 2000)\n",
      "('read data: ', 'bitcoin', 5000, 2000)\n",
      "('read data: ', 'bitcoin_caida/1', 5000, 2000)\n",
      "('read data: ', 'bitcoin_caida/2', 5000, 2000)\n",
      "('read data: ', 'bitcoin_caida/3', 5000, 2000)\n",
      "('read data: ', 'bitcoin_caida/4', 5000, 2000)\n",
      "('read data: ', 'bitcoin_caida/5', 5000, 2000)\n",
      "('Time it took: ', 1219.6898741722107)\n"
     ]
    }
   ],
   "source": [
    "import time \n",
    "\n",
    "begin = time.time()\n",
    "(x_train, y_train), (x_test, y_test) = read_train_test_2()\n",
    "XTrain, yTrain = np.array(x_train), np.array(y_train)\n",
    "xTest, yTest = np.array(x_test), np.array(y_test) \n",
    "print(\"Time it took: \", time.time() - begin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, BatchNormalization, Dropout, Conv1D, MaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.layers.core import Activation\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import LeakyReLU, ReLU\n",
    "\n",
    "\n",
    "def get_bitcoin_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv1D(32, 1, input_shape = (1, 60)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(16))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_NN_model(flow_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(64, 1, activation='relu',input_shape=(1, flow_size)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def get_NN_model_3(flow_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(512, 1, input_shape=(1, flow_size)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model.add(Conv1D(128, 1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model.add(Conv1D(128, 1))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(16,kernel_regularizer=l2(1e-5), bias_regularizer=l2(1e-5)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    return model\n",
    "'''\n",
    " \n",
    "    conv_dec_3 = Conv1D(filters = 10, kernel_size=10,kernel_regularizer=l2(reg), padding='same', name='conv_dec_3')(max_pool_dec_2)\n",
    "    conv_batch_3 = BatchNormalization(name='conv_batch_3_dec')(conv_dec_3)\n",
    "    conv_relu_3 = Activation('relu', name='conv_relu_3_dec')(conv_batch_3)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_3_dec')(conv_relu_3)\n",
    "    max_pool_dec_3 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_3\")(conv_drop_2)\n",
    "\n",
    "'''\n",
    "def get_NN_model_2(flow_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(1024, 1, activation='relu', input_shape=(1, flow_size)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model.add(Conv1D(256, 1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "#     model.add(Conv1D(64, 1, activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(32,kernel_regularizer=l2(1e-5), bias_regularizer=l2(1e-5), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_NN_model_2(flow_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv1D(1024, 1, activation='relu', input_shape=(1, flow_size)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    \n",
    "    model.add(Conv1D(128, 1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    model.add(Conv1D(64, 1, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(MaxPooling1D(pool_size=1))\n",
    "    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(32, kernel_regularizer=l2(1e-5), bias_regularizer=l2(1e-5), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "#     model.add(Dense(16, kernel_regularizer=l2(1e-5), bias_regularizer=l2(1e-5), activation='relu'))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 2)\n",
    "pca = pca.fit_transform(XTrain2)\n",
    "\n",
    "x = pca[:, 1]#[:100]\n",
    "y = pca[:, 0]#[:100]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "neg = 50000\n",
    "plt.scatter(x[:100],y[:100])\n",
    "plt.scatter(x[neg:neg+100],y[neg:neg+100])\n",
    "# plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "def shuffle_transform(X, y):\n",
    "    \n",
    "    order = np.arange(X.shape[0])\n",
    "    np.random.shuffle(order)\n",
    "\n",
    "    XT = X[order]\n",
    "    yT = y[order]\n",
    "\n",
    "    XT = scaler.fit_transform(XT)## train\n",
    "    XT = np.expand_dims(XT, axis = 1)\n",
    "    return XT, yT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT, yT = shuffle_transform(XTrain, yTrain)\n",
    "xt, yt = shuffle_transform(xTest, yTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "order = np.arange(XTrain.shape[0])\n",
    "np.random.shuffle(order)\n",
    "\n",
    "XT = XTrain[order]\n",
    "yT = yTrain[order]\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "XT = scaler.fit_transform(XT)\n",
    "XT = np.expand_dims(XT, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTest2 = scaler.fit_transform(xTest)\n",
    "xTest2 = np.expand_dims(xTest2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "es = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode='max', min_delta=0, patience = 20,restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/60\n",
      "36000/36000 [==============================] - 38s 1ms/step - loss: 0.0680 - accuracy: 0.9801 - val_loss: 1.2974 - val_accuracy: 0.5098\n",
      "Epoch 2/60\n",
      "36000/36000 [==============================] - 40s 1ms/step - loss: 0.0070 - accuracy: 0.9997 - val_loss: 1.7983 - val_accuracy: 0.5098\n",
      "Epoch 3/60\n",
      "36000/36000 [==============================] - 38s 1ms/step - loss: 0.0037 - accuracy: 0.9998 - val_loss: 1.7333 - val_accuracy: 0.5098\n",
      "Epoch 4/60\n",
      "36000/36000 [==============================] - 36s 1ms/step - loss: 0.0028 - accuracy: 0.9998 - val_loss: 1.3696 - val_accuracy: 0.5217\n",
      "Epoch 5/60\n",
      "36000/36000 [==============================] - 42s 1ms/step - loss: 0.0025 - accuracy: 0.9998 - val_loss: 0.3688 - val_accuracy: 0.7638\n",
      "Epoch 6/60\n",
      "36000/36000 [==============================] - 45s 1ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.2657 - val_accuracy: 0.8525\n",
      "Epoch 7/60\n",
      "36000/36000 [==============================] - 42s 1ms/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0957 - val_accuracy: 0.9572\n",
      "Epoch 8/60\n",
      "36000/36000 [==============================] - 41s 1ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9990\n",
      "Epoch 9/60\n",
      "36000/36000 [==============================] - 39s 1ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.0097 - val_accuracy: 0.9973\n",
      "Epoch 10/60\n",
      "36000/36000 [==============================] - 35s 983us/step - loss: 0.0014 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9995\n",
      "Epoch 11/60\n",
      "36000/36000 [==============================] - 34s 940us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0056 - val_accuracy: 0.9992\n",
      "Epoch 12/60\n",
      "36000/36000 [==============================] - 33s 916us/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0052 - val_accuracy: 0.9992\n",
      "Epoch 13/60\n",
      "36000/36000 [==============================] - 23s 625us/step - loss: 9.0674e-04 - accuracy: 0.9999 - val_loss: 0.0048 - val_accuracy: 0.9995\n",
      "Epoch 14/60\n",
      "36000/36000 [==============================] - 17s 480us/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 0.0072 - val_accuracy: 0.9990\n",
      "Epoch 15/60\n",
      "36000/36000 [==============================] - 17s 478us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9990\n",
      "Epoch 16/60\n",
      "36000/36000 [==============================] - 17s 481us/step - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
      "Epoch 17/60\n",
      "36000/36000 [==============================] - 17s 477us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0077 - val_accuracy: 0.9985\n",
      "Epoch 18/60\n",
      "36000/36000 [==============================] - 17s 481us/step - loss: 6.3199e-04 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 0.9992\n",
      "Epoch 19/60\n",
      "36000/36000 [==============================] - 17s 477us/step - loss: 5.9640e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
      "Epoch 20/60\n",
      "36000/36000 [==============================] - 17s 475us/step - loss: 6.0813e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9990\n",
      "Epoch 21/60\n",
      "36000/36000 [==============================] - 17s 470us/step - loss: 0.0016 - accuracy: 0.9997 - val_loss: 0.0050 - val_accuracy: 0.9995\n",
      "Epoch 22/60\n",
      "36000/36000 [==============================] - 17s 472us/step - loss: 7.9221e-04 - accuracy: 0.9999 - val_loss: 0.0050 - val_accuracy: 0.9995\n",
      "Epoch 23/60\n",
      "36000/36000 [==============================] - 17s 474us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0203 - val_accuracy: 0.9920\n",
      "Epoch 24/60\n",
      "36000/36000 [==============================] - 17s 475us/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
      "Epoch 25/60\n",
      "36000/36000 [==============================] - 17s 474us/step - loss: 4.8974e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
      "Epoch 26/60\n",
      "36000/36000 [==============================] - 17s 473us/step - loss: 5.1923e-04 - accuracy: 0.9999 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "Epoch 27/60\n",
      "36000/36000 [==============================] - 17s 473us/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 28/60\n",
      "36000/36000 [==============================] - 17s 474us/step - loss: 8.3577e-04 - accuracy: 0.9999 - val_loss: 0.0055 - val_accuracy: 0.9995\n",
      "Epoch 29/60\n",
      "36000/36000 [==============================] - 17s 481us/step - loss: 4.3491e-04 - accuracy: 1.0000 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
      "Epoch 30/60\n",
      "36000/36000 [==============================] - 17s 473us/step - loss: 4.1685e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9995\n",
      "Epoch 31/60\n",
      "36000/36000 [==============================] - 17s 471us/step - loss: 4.1539e-04 - accuracy: 1.0000 - val_loss: 0.0056 - val_accuracy: 0.9995\n",
      "Epoch 32/60\n",
      "36000/36000 [==============================] - 17s 480us/step - loss: 4.2982e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "Epoch 33/60\n",
      "36000/36000 [==============================] - 17s 479us/step - loss: 3.9366e-04 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 0.9995\n",
      "Epoch 34/60\n",
      "36000/36000 [==============================] - 17s 476us/step - loss: 3.7116e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "Epoch 35/60\n",
      "36000/36000 [==============================] - 17s 476us/step - loss: 3.7863e-04 - accuracy: 1.0000 - val_loss: 0.0053 - val_accuracy: 0.9995\n",
      "Epoch 36/60\n",
      "36000/36000 [==============================] - 17s 471us/step - loss: 5.3950e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
      "Epoch 37/60\n",
      "36000/36000 [==============================] - 17s 478us/step - loss: 4.0993e-04 - accuracy: 0.9999 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
      "Epoch 38/60\n",
      "36000/36000 [==============================] - 17s 474us/step - loss: 4.4860e-04 - accuracy: 0.9999 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
      "Epoch 39/60\n",
      "36000/36000 [==============================] - 17s 476us/step - loss: 9.1537e-04 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9985\n",
      "Epoch 40/60\n",
      "36000/36000 [==============================] - 17s 476us/step - loss: 6.7820e-04 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9995\n",
      "Epoch 41/60\n",
      "36000/36000 [==============================] - 17s 476us/step - loss: 5.9761e-04 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 42/60\n",
      "36000/36000 [==============================] - 17s 477us/step - loss: 6.4549e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 43/60\n",
      "36000/36000 [==============================] - 17s 472us/step - loss: 7.1905e-04 - accuracy: 0.9999 - val_loss: 0.0059 - val_accuracy: 0.9992\n",
      "Epoch 44/60\n",
      "36000/36000 [==============================] - 17s 473us/step - loss: 6.9929e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
      "Epoch 45/60\n",
      "36000/36000 [==============================] - 17s 473us/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
      "Epoch 46/60\n",
      "36000/36000 [==============================] - 17s 477us/step - loss: 3.6550e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
      "Epoch 47/60\n",
      "36000/36000 [==============================] - 17s 470us/step - loss: 3.0974e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
      "Epoch 48/60\n",
      "36000/36000 [==============================] - 17s 480us/step - loss: 2.9861e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
      "Epoch 49/60\n",
      "36000/36000 [==============================] - 17s 478us/step - loss: 2.9668e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
      "Epoch 50/60\n",
      "36000/36000 [==============================] - 17s 471us/step - loss: 2.9649e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9992\n",
      "Epoch 51/60\n",
      "36000/36000 [==============================] - 17s 476us/step - loss: 2.9461e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9992\n",
      "Epoch 52/60\n",
      "36000/36000 [==============================] - 17s 478us/step - loss: 2.6897e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
      "Epoch 53/60\n",
      "36000/36000 [==============================] - 17s 474us/step - loss: 2.6104e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
      "Epoch 54/60\n",
      "36000/36000 [==============================] - 17s 470us/step - loss: 2.5271e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
      "Epoch 55/60\n",
      "36000/36000 [==============================] - 17s 475us/step - loss: 2.4517e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
      "Epoch 56/60\n",
      "36000/36000 [==============================] - 17s 467us/step - loss: 6.7492e-04 - accuracy: 0.9999 - val_loss: 0.0057 - val_accuracy: 0.9995\n",
      "Epoch 57/60\n",
      "36000/36000 [==============================] - 17s 467us/step - loss: 6.9278e-04 - accuracy: 0.9998 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 58/60\n",
      "36000/36000 [==============================] - 17s 477us/step - loss: 7.4203e-04 - accuracy: 0.9999 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 59/60\n",
      "36000/36000 [==============================] - 17s 471us/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0071 - val_accuracy: 0.9990\n",
      "Epoch 60/60\n",
      "36000/36000 [==============================] - 17s 477us/step - loss: 0.0010 - accuracy: 0.9999 - val_loss: 0.0077 - val_accuracy: 0.9992\n",
      "('Time it takes to fit: ', 1295.5335929393768)\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import seed\n",
    "import random\n",
    "import time\n",
    "from keras.initializers import normal\n",
    "# initializer = normal(mean=0, stddev=0.01, seed=13)\n",
    "seed(1)\n",
    "random.seed(1)\n",
    "epochs = 60\n",
    "n_train = 40 * 1000\n",
    "\n",
    "model = get_NN_model_2(flow_size = 1576)#get_bitcoin_model()#get_NN_model()#get_Dense_NN_model\n",
    "\n",
    "start = time.time()\n",
    "history = model.fit(XT[:n_train,:,:], yT[:n_train],epochs = 60, batch_size = 512, verbose = 1, validation_split=0.1)\n",
    "end = time.time()\n",
    "print (\"Time it takes to fit: \", end - start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36000 samples, validate on 4000 samples\n",
      "Epoch 1/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 2.3631e-04 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9992\n",
      "Epoch 2/940\n",
      "36000/36000 [==============================] - 20s 559us/step - loss: 6.0181e-04 - accuracy: 0.9999 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 3/940\n",
      "36000/36000 [==============================] - 18s 511us/step - loss: 2.4240e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
      "Epoch 4/940\n",
      "36000/36000 [==============================] - 17s 485us/step - loss: 2.2921e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9992\n",
      "Epoch 5/940\n",
      "36000/36000 [==============================] - 19s 524us/step - loss: 2.1239e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
      "Epoch 6/940\n",
      "36000/36000 [==============================] - 20s 555us/step - loss: 2.0778e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
      "Epoch 7/940\n",
      "36000/36000 [==============================] - 18s 492us/step - loss: 2.0234e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9992\n",
      "Epoch 8/940\n",
      "36000/36000 [==============================] - 18s 502us/step - loss: 1.9540e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
      "Epoch 9/940\n",
      "36000/36000 [==============================] - 18s 506us/step - loss: 1.9142e-04 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9992\n",
      "Epoch 10/940\n",
      "36000/36000 [==============================] - 18s 497us/step - loss: 1.9628e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
      "Epoch 11/940\n",
      "36000/36000 [==============================] - 17s 481us/step - loss: 2.1514e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9992\n",
      "Epoch 12/940\n",
      "36000/36000 [==============================] - 18s 492us/step - loss: 1.7477e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 13/940\n",
      "36000/36000 [==============================] - 18s 487us/step - loss: 1.6946e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9992\n",
      "Epoch 14/940\n",
      "36000/36000 [==============================] - 18s 487us/step - loss: 1.6300e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9992\n",
      "Epoch 15/940\n",
      "36000/36000 [==============================] - 17s 478us/step - loss: 1.5659e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9992\n",
      "Epoch 16/940\n",
      "36000/36000 [==============================] - 18s 490us/step - loss: 1.5097e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9992\n",
      "Epoch 17/940\n",
      "36000/36000 [==============================] - 19s 519us/step - loss: 1.5113e-04 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 0.9992\n",
      "Epoch 18/940\n",
      "36000/36000 [==============================] - 19s 528us/step - loss: 1.4670e-04 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9992\n",
      "Epoch 19/940\n",
      "36000/36000 [==============================] - 20s 554us/step - loss: 1.3934e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9992\n",
      "Epoch 20/940\n",
      "36000/36000 [==============================] - 18s 492us/step - loss: 1.3186e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9992\n",
      "Epoch 21/940\n",
      "36000/36000 [==============================] - 18s 493us/step - loss: 1.2819e-04 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9992\n",
      "Epoch 22/940\n",
      "36000/36000 [==============================] - 18s 495us/step - loss: 1.2113e-04 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9992\n",
      "Epoch 23/940\n",
      "36000/36000 [==============================] - 18s 499us/step - loss: 1.1611e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9992\n",
      "Epoch 24/940\n",
      "36000/36000 [==============================] - 18s 491us/step - loss: 1.1118e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 25/940\n",
      "36000/36000 [==============================] - 17s 482us/step - loss: 1.0782e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 26/940\n",
      "36000/36000 [==============================] - 18s 488us/step - loss: 1.0247e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 27/940\n",
      "36000/36000 [==============================] - 18s 490us/step - loss: 9.7918e-05 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9992\n",
      "Epoch 28/940\n",
      "36000/36000 [==============================] - 18s 492us/step - loss: 9.3473e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 29/940\n",
      "36000/36000 [==============================] - 18s 501us/step - loss: 8.8819e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 30/940\n",
      "36000/36000 [==============================] - 18s 491us/step - loss: 8.4298e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 31/940\n",
      "36000/36000 [==============================] - 18s 486us/step - loss: 7.9655e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 32/940\n",
      "36000/36000 [==============================] - 17s 480us/step - loss: 7.5741e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 33/940\n",
      "36000/36000 [==============================] - 18s 487us/step - loss: 7.1663e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 34/940\n",
      "36000/36000 [==============================] - 18s 489us/step - loss: 6.8248e-05 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 35/940\n",
      "36000/36000 [==============================] - 18s 487us/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0083 - val_accuracy: 0.9992\n",
      "Epoch 36/940\n",
      "36000/36000 [==============================] - 17s 481us/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.0126 - val_accuracy: 0.9973\n",
      "Epoch 37/940\n",
      "36000/36000 [==============================] - 18s 501us/step - loss: 7.2072e-04 - accuracy: 0.9998 - val_loss: 0.0061 - val_accuracy: 0.9995\n",
      "Epoch 38/940\n",
      "36000/36000 [==============================] - 18s 512us/step - loss: 2.2798e-04 - accuracy: 0.9999 - val_loss: 0.0054 - val_accuracy: 0.9992\n",
      "Epoch 39/940\n",
      "36000/36000 [==============================] - 17s 478us/step - loss: 1.6699e-04 - accuracy: 1.0000 - val_loss: 0.0060 - val_accuracy: 0.9992\n",
      "Epoch 40/940\n",
      "36000/36000 [==============================] - 18s 492us/step - loss: 5.9568e-04 - accuracy: 0.9999 - val_loss: 0.0056 - val_accuracy: 0.9995\n",
      "Epoch 41/940\n",
      "36000/36000 [==============================] - 17s 478us/step - loss: 1.1544e-04 - accuracy: 1.0000 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "Epoch 42/940\n",
      "36000/36000 [==============================] - 17s 478us/step - loss: 3.5919e-04 - accuracy: 0.9999 - val_loss: 0.0058 - val_accuracy: 0.9995\n",
      "Epoch 43/940\n",
      "36000/36000 [==============================] - 17s 482us/step - loss: 2.4499e-04 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "Epoch 44/940\n",
      "36000/36000 [==============================] - 17s 479us/step - loss: 1.0729e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 45/940\n",
      "36000/36000 [==============================] - 17s 484us/step - loss: 1.0180e-04 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9992\n",
      "Epoch 46/940\n",
      "36000/36000 [==============================] - 18s 504us/step - loss: 9.1123e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9992\n",
      "Epoch 47/940\n",
      "36000/36000 [==============================] - 18s 491us/step - loss: 8.7283e-05 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9992\n",
      "Epoch 48/940\n",
      "36000/36000 [==============================] - 18s 493us/step - loss: 8.6674e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9992\n",
      "Epoch 49/940\n",
      "36000/36000 [==============================] - 18s 497us/step - loss: 8.1766e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9992\n",
      "Epoch 50/940\n",
      "36000/36000 [==============================] - 18s 503us/step - loss: 7.7307e-05 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9992\n",
      "Epoch 51/940\n",
      "36000/36000 [==============================] - 18s 497us/step - loss: 5.0943e-04 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 52/940\n",
      "36000/36000 [==============================] - 18s 502us/step - loss: 2.0290e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9992\n",
      "Epoch 53/940\n",
      "36000/36000 [==============================] - 18s 495us/step - loss: 8.8399e-05 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9992\n",
      "Epoch 54/940\n",
      "36000/36000 [==============================] - 18s 488us/step - loss: 1.2578e-04 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9992\n",
      "Epoch 55/940\n",
      "36000/36000 [==============================] - 18s 496us/step - loss: 9.8984e-04 - accuracy: 0.9998 - val_loss: 0.0091 - val_accuracy: 0.9992\n",
      "Epoch 56/940\n",
      "36000/36000 [==============================] - 17s 486us/step - loss: 3.0804e-04 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9995\n",
      "Epoch 57/940\n",
      "36000/36000 [==============================] - 18s 487us/step - loss: 5.9895e-04 - accuracy: 0.9998 - val_loss: 0.0079 - val_accuracy: 0.9992\n",
      "Epoch 58/940\n",
      "36000/36000 [==============================] - 18s 491us/step - loss: 7.1296e-04 - accuracy: 0.9999 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "Epoch 59/940\n",
      "36000/36000 [==============================] - 18s 513us/step - loss: 1.7491e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 60/940\n",
      "36000/36000 [==============================] - 17s 484us/step - loss: 9.2988e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "Epoch 61/940\n",
      "36000/36000 [==============================] - 18s 507us/step - loss: 1.3022e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 62/940\n",
      "36000/36000 [==============================] - 18s 489us/step - loss: 7.7857e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 63/940\n",
      "36000/36000 [==============================] - 18s 502us/step - loss: 1.2776e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 64/940\n",
      "36000/36000 [==============================] - 17s 485us/step - loss: 8.1558e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 65/940\n",
      "36000/36000 [==============================] - 18s 487us/step - loss: 7.0704e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 66/940\n",
      "36000/36000 [==============================] - 18s 497us/step - loss: 7.1303e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 67/940\n",
      "36000/36000 [==============================] - 18s 494us/step - loss: 6.6131e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 68/940\n",
      "36000/36000 [==============================] - 18s 491us/step - loss: 6.1918e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 69/940\n",
      "36000/36000 [==============================] - 18s 495us/step - loss: 6.0783e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 70/940\n",
      "36000/36000 [==============================] - 18s 490us/step - loss: 5.7928e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 71/940\n",
      "36000/36000 [==============================] - 18s 493us/step - loss: 5.6016e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 72/940\n",
      "36000/36000 [==============================] - 18s 495us/step - loss: 2.6439e-04 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9992\n",
      "Epoch 73/940\n",
      "36000/36000 [==============================] - 18s 495us/step - loss: 1.1189e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 74/940\n",
      "36000/36000 [==============================] - 18s 497us/step - loss: 1.2742e-04 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 75/940\n",
      "36000/36000 [==============================] - 18s 511us/step - loss: 2.2214e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 76/940\n",
      "36000/36000 [==============================] - 18s 500us/step - loss: 4.2138e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 77/940\n",
      "36000/36000 [==============================] - 18s 497us/step - loss: 6.4736e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 78/940\n",
      "36000/36000 [==============================] - 18s 495us/step - loss: 5.4491e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 79/940\n",
      "36000/36000 [==============================] - 18s 501us/step - loss: 3.3179e-04 - accuracy: 0.9999 - val_loss: 0.0062 - val_accuracy: 0.9995\n",
      "Epoch 80/940\n",
      "36000/36000 [==============================] - 18s 496us/step - loss: 5.9195e-04 - accuracy: 0.9999 - val_loss: 0.0055 - val_accuracy: 0.9995\n",
      "Epoch 81/940\n",
      "36000/36000 [==============================] - 18s 497us/step - loss: 6.6477e-05 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
      "Epoch 82/940\n",
      "36000/36000 [==============================] - 18s 498us/step - loss: 5.6120e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
      "Epoch 83/940\n",
      "36000/36000 [==============================] - 18s 503us/step - loss: 5.1391e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9992\n",
      "Epoch 84/940\n",
      "36000/36000 [==============================] - 18s 498us/step - loss: 3.5601e-04 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 85/940\n",
      "36000/36000 [==============================] - 18s 493us/step - loss: 2.6402e-04 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 86/940\n",
      "36000/36000 [==============================] - 19s 528us/step - loss: 5.6114e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 87/940\n",
      "36000/36000 [==============================] - 19s 521us/step - loss: 6.0704e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 88/940\n",
      "36000/36000 [==============================] - 19s 526us/step - loss: 1.7369e-04 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9992\n",
      "Epoch 89/940\n",
      "36000/36000 [==============================] - 18s 510us/step - loss: 1.5788e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 90/940\n",
      "36000/36000 [==============================] - 18s 503us/step - loss: 2.0562e-04 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
      "Epoch 91/940\n",
      "36000/36000 [==============================] - 18s 508us/step - loss: 5.4495e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 92/940\n",
      "36000/36000 [==============================] - 18s 497us/step - loss: 4.9525e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 93/940\n",
      "36000/36000 [==============================] - 18s 499us/step - loss: 4.5384e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 94/940\n",
      "36000/36000 [==============================] - 18s 500us/step - loss: 4.3247e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 95/940\n",
      "36000/36000 [==============================] - 18s 505us/step - loss: 4.0601e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 96/940\n",
      "36000/36000 [==============================] - 18s 502us/step - loss: 2.6278e-04 - accuracy: 0.9999 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 97/940\n",
      "36000/36000 [==============================] - 18s 514us/step - loss: 2.2769e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 98/940\n",
      "36000/36000 [==============================] - 18s 502us/step - loss: 4.6242e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 99/940\n",
      "36000/36000 [==============================] - 18s 501us/step - loss: 4.0724e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 100/940\n",
      "36000/36000 [==============================] - 18s 505us/step - loss: 3.9414e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 101/940\n",
      "36000/36000 [==============================] - 18s 504us/step - loss: 3.8037e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 102/940\n",
      "36000/36000 [==============================] - 18s 500us/step - loss: 3.6469e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 103/940\n",
      "36000/36000 [==============================] - 19s 526us/step - loss: 3.4669e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 104/940\n",
      "36000/36000 [==============================] - 19s 519us/step - loss: 3.6591e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 105/940\n",
      "36000/36000 [==============================] - 19s 519us/step - loss: 3.5026e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 106/940\n",
      "36000/36000 [==============================] - 19s 521us/step - loss: 6.8099e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9992\n",
      "Epoch 107/940\n",
      "36000/36000 [==============================] - 18s 500us/step - loss: 5.9992e-04 - accuracy: 0.9999 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
      "Epoch 108/940\n",
      "36000/36000 [==============================] - 18s 513us/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 109/940\n",
      "36000/36000 [==============================] - 18s 507us/step - loss: 1.9116e-04 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 110/940\n",
      "36000/36000 [==============================] - 18s 507us/step - loss: 7.0380e-05 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 0.9995\n",
      "Epoch 111/940\n",
      "36000/36000 [==============================] - 18s 507us/step - loss: 6.4658e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "Epoch 112/940\n",
      "36000/36000 [==============================] - 18s 509us/step - loss: 5.4299e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "Epoch 113/940\n",
      "36000/36000 [==============================] - 18s 505us/step - loss: 5.0108e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "Epoch 114/940\n",
      "36000/36000 [==============================] - 18s 505us/step - loss: 2.4893e-04 - accuracy: 0.9999 - val_loss: 0.0059 - val_accuracy: 0.9995\n",
      "Epoch 115/940\n",
      "36000/36000 [==============================] - 18s 502us/step - loss: 2.9999e-04 - accuracy: 0.9999 - val_loss: 0.0081 - val_accuracy: 0.9995\n",
      "Epoch 116/940\n",
      "36000/36000 [==============================] - 18s 512us/step - loss: 1.9304e-04 - accuracy: 0.9999 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 117/940\n",
      "36000/36000 [==============================] - 18s 508us/step - loss: 5.2331e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 118/940\n",
      "36000/36000 [==============================] - 19s 523us/step - loss: 5.3646e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 119/940\n",
      "36000/36000 [==============================] - 19s 518us/step - loss: 1.2250e-04 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 120/940\n",
      "36000/36000 [==============================] - 18s 506us/step - loss: 6.4013e-04 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 121/940\n",
      "36000/36000 [==============================] - 18s 508us/step - loss: 1.5080e-04 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 122/940\n",
      "36000/36000 [==============================] - 19s 521us/step - loss: 4.5053e-04 - accuracy: 0.9999 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 123/940\n",
      "36000/36000 [==============================] - 19s 514us/step - loss: 5.6885e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 124/940\n",
      "36000/36000 [==============================] - 18s 509us/step - loss: 2.4587e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 125/940\n",
      "36000/36000 [==============================] - 19s 537us/step - loss: 7.0345e-05 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 126/940\n",
      "36000/36000 [==============================] - 19s 515us/step - loss: 4.6720e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 127/940\n",
      "36000/36000 [==============================] - 19s 515us/step - loss: 5.3806e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 128/940\n",
      "36000/36000 [==============================] - 20s 552us/step - loss: 4.0989e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 129/940\n",
      "36000/36000 [==============================] - 19s 526us/step - loss: 5.3363e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 130/940\n",
      "36000/36000 [==============================] - 19s 535us/step - loss: 3.9203e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 131/940\n",
      "36000/36000 [==============================] - 19s 521us/step - loss: 3.5545e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 132/940\n",
      "36000/36000 [==============================] - 19s 522us/step - loss: 3.3790e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 133/940\n",
      "36000/36000 [==============================] - 19s 528us/step - loss: 3.2118e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 134/940\n",
      "36000/36000 [==============================] - 19s 515us/step - loss: 3.0931e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 135/940\n",
      "36000/36000 [==============================] - 19s 517us/step - loss: 2.9462e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 136/940\n",
      "36000/36000 [==============================] - 19s 517us/step - loss: 2.8048e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 137/940\n",
      "36000/36000 [==============================] - 19s 521us/step - loss: 2.7498e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 138/940\n",
      "36000/36000 [==============================] - 19s 533us/step - loss: 4.0432e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 139/940\n",
      "36000/36000 [==============================] - 19s 532us/step - loss: 1.2582e-04 - accuracy: 0.9999 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 140/940\n",
      "36000/36000 [==============================] - 21s 578us/step - loss: 7.3027e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 141/940\n",
      "36000/36000 [==============================] - 20s 549us/step - loss: 3.5825e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 142/940\n",
      "36000/36000 [==============================] - 19s 525us/step - loss: 3.2522e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 143/940\n",
      "36000/36000 [==============================] - 21s 575us/step - loss: 3.1259e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 144/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 7.4739e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 145/940\n",
      "36000/36000 [==============================] - 19s 527us/step - loss: 3.3113e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 146/940\n",
      "36000/36000 [==============================] - 19s 520us/step - loss: 2.8102e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 147/940\n",
      "36000/36000 [==============================] - 19s 530us/step - loss: 2.5934e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 148/940\n",
      "36000/36000 [==============================] - 19s 529us/step - loss: 2.4947e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 149/940\n",
      "36000/36000 [==============================] - 20s 563us/step - loss: 2.3234e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 150/940\n",
      "36000/36000 [==============================] - 20s 547us/step - loss: 2.2950e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 151/940\n",
      "36000/36000 [==============================] - 19s 530us/step - loss: 2.1194e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 152/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 2.0054e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 153/940\n",
      "36000/36000 [==============================] - 19s 534us/step - loss: 1.8822e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 154/940\n",
      "36000/36000 [==============================] - 19s 525us/step - loss: 1.7537e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 155/940\n",
      "36000/36000 [==============================] - 20s 562us/step - loss: 1.6691e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 156/940\n",
      "36000/36000 [==============================] - 20s 545us/step - loss: 1.5496e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 157/940\n",
      "36000/36000 [==============================] - 20s 567us/step - loss: 1.4625e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 158/940\n",
      "36000/36000 [==============================] - 20s 553us/step - loss: 1.3896e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 159/940\n",
      "36000/36000 [==============================] - 21s 571us/step - loss: 4.6024e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 160/940\n",
      "36000/36000 [==============================] - 20s 566us/step - loss: 3.7330e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 161/940\n",
      "36000/36000 [==============================] - 22s 622us/step - loss: 9.4151e-05 - accuracy: 0.9999 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 162/940\n",
      "36000/36000 [==============================] - 21s 597us/step - loss: 4.6784e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 163/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 3.3253e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 164/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 3.3970e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 165/940\n",
      "36000/36000 [==============================] - 20s 555us/step - loss: 1.7405e-04 - accuracy: 0.9999 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
      "Epoch 166/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 5.5755e-04 - accuracy: 0.9999 - val_loss: 0.0130 - val_accuracy: 0.9983\n",
      "Epoch 167/940\n",
      "36000/36000 [==============================] - 21s 596us/step - loss: 7.0384e-04 - accuracy: 0.9998 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 168/940\n",
      "36000/36000 [==============================] - 19s 525us/step - loss: 2.7971e-04 - accuracy: 0.9999 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 169/940\n",
      "36000/36000 [==============================] - 19s 529us/step - loss: 6.1673e-04 - accuracy: 0.9999 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 170/940\n",
      "36000/36000 [==============================] - 19s 518us/step - loss: 7.0043e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 171/940\n",
      "36000/36000 [==============================] - 19s 519us/step - loss: 7.6954e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 172/940\n",
      "36000/36000 [==============================] - 19s 520us/step - loss: 1.3145e-04 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 173/940\n",
      "36000/36000 [==============================] - 19s 527us/step - loss: 5.0948e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 174/940\n",
      "36000/36000 [==============================] - 19s 525us/step - loss: 4.6199e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 175/940\n",
      "36000/36000 [==============================] - 19s 534us/step - loss: 7.1988e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 176/940\n",
      "36000/36000 [==============================] - 19s 532us/step - loss: 2.9337e-04 - accuracy: 0.9999 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 177/940\n",
      "36000/36000 [==============================] - 19s 531us/step - loss: 4.3341e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 178/940\n",
      "36000/36000 [==============================] - 19s 533us/step - loss: 4.8381e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 179/940\n",
      "36000/36000 [==============================] - 19s 533us/step - loss: 1.1589e-04 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9992\n",
      "Epoch 180/940\n",
      "36000/36000 [==============================] - 19s 530us/step - loss: 4.7677e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 181/940\n",
      "36000/36000 [==============================] - 19s 536us/step - loss: 6.7434e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 182/940\n",
      "36000/36000 [==============================] - 19s 535us/step - loss: 1.6285e-04 - accuracy: 0.9999 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 183/940\n",
      "36000/36000 [==============================] - 19s 536us/step - loss: 4.0297e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 184/940\n",
      "36000/36000 [==============================] - 19s 532us/step - loss: 3.7384e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 185/940\n",
      "36000/36000 [==============================] - 19s 533us/step - loss: 1.3639e-04 - accuracy: 1.0000 - val_loss: 0.0085 - val_accuracy: 0.9992\n",
      "Epoch 186/940\n",
      "36000/36000 [==============================] - 19s 533us/step - loss: 5.9195e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 187/940\n",
      "36000/36000 [==============================] - 19s 533us/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0064 - val_accuracy: 0.9992\n",
      "Epoch 188/940\n",
      "36000/36000 [==============================] - 19s 533us/step - loss: 6.0638e-04 - accuracy: 0.9998 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 189/940\n",
      "36000/36000 [==============================] - 19s 531us/step - loss: 1.0081e-04 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 190/940\n",
      "36000/36000 [==============================] - 19s 536us/step - loss: 1.3587e-04 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 191/940\n",
      "36000/36000 [==============================] - 19s 535us/step - loss: 9.5337e-05 - accuracy: 1.0000 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
      "Epoch 192/940\n",
      "36000/36000 [==============================] - 19s 532us/step - loss: 5.8826e-05 - accuracy: 1.0000 - val_loss: 0.0064 - val_accuracy: 0.9995\n",
      "Epoch 193/940\n",
      "36000/36000 [==============================] - 19s 531us/step - loss: 5.3995e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 194/940\n",
      "36000/36000 [==============================] - 19s 535us/step - loss: 5.1000e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 195/940\n",
      "36000/36000 [==============================] - 19s 538us/step - loss: 5.0460e-05 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 196/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 4.7821e-05 - accuracy: 1.0000 - val_loss: 0.0067 - val_accuracy: 0.9995\n",
      "Epoch 197/940\n",
      "36000/36000 [==============================] - 20s 543us/step - loss: 5.5787e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 198/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 4.1442e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 199/940\n",
      "36000/36000 [==============================] - 20s 544us/step - loss: 3.8362e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 200/940\n",
      "36000/36000 [==============================] - 19s 541us/step - loss: 3.8963e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 201/940\n",
      "36000/36000 [==============================] - 19s 541us/step - loss: 4.0391e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 202/940\n",
      "36000/36000 [==============================] - 20s 543us/step - loss: 3.3820e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 203/940\n",
      "36000/36000 [==============================] - 20s 542us/step - loss: 3.1805e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 204/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 2.9756e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 205/940\n",
      "36000/36000 [==============================] - 20s 543us/step - loss: 3.4330e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 206/940\n",
      "36000/36000 [==============================] - 20s 542us/step - loss: 3.0024e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9995\n",
      "Epoch 207/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 3.9800e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 208/940\n",
      "36000/36000 [==============================] - 19s 541us/step - loss: 2.5504e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 209/940\n",
      "36000/36000 [==============================] - 19s 541us/step - loss: 2.4749e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 210/940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36000/36000 [==============================] - 19s 540us/step - loss: 2.3182e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 211/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 2.2580e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 212/940\n",
      "36000/36000 [==============================] - 20s 543us/step - loss: 2.0243e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 213/940\n",
      "36000/36000 [==============================] - 20s 542us/step - loss: 1.8826e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 214/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 1.8862e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 215/940\n",
      "36000/36000 [==============================] - 19s 538us/step - loss: 1.7195e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 216/940\n",
      "36000/36000 [==============================] - 19s 537us/step - loss: 1.7039e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 217/940\n",
      "36000/36000 [==============================] - 20s 544us/step - loss: 1.4688e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 218/940\n",
      "36000/36000 [==============================] - 20s 544us/step - loss: 1.4240e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 219/940\n",
      "36000/36000 [==============================] - 19s 538us/step - loss: 1.3436e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 220/940\n",
      "36000/36000 [==============================] - 20s 542us/step - loss: 1.2222e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 221/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 1.1562e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 222/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 1.0725e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 223/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 9.8604e-06 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 224/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 9.3230e-06 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 225/940\n",
      "36000/36000 [==============================] - 19s 538us/step - loss: 8.9514e-06 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 226/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 9.0378e-06 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 227/940\n",
      "36000/36000 [==============================] - 20s 543us/step - loss: 8.0629e-06 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 228/940\n",
      "36000/36000 [==============================] - 19s 541us/step - loss: 7.3694e-06 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 229/940\n",
      "36000/36000 [==============================] - 20s 543us/step - loss: 6.9828e-06 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
      "Epoch 230/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 6.9915e-06 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 231/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 6.2716e-06 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 232/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 5.4119e-06 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 233/940\n",
      "36000/36000 [==============================] - 20s 542us/step - loss: 5.2241e-06 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
      "Epoch 234/940\n",
      "36000/36000 [==============================] - 19s 542us/step - loss: 6.9889e-06 - accuracy: 1.0000 - val_loss: 0.0065 - val_accuracy: 0.9995\n",
      "Epoch 235/940\n",
      "36000/36000 [==============================] - 19s 541us/step - loss: 9.2858e-06 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
      "Epoch 236/940\n",
      "36000/36000 [==============================] - 19s 538us/step - loss: 7.6699e-06 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9995\n",
      "Epoch 237/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 5.9622e-06 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 0.9995\n",
      "Epoch 238/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 5.9034e-06 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
      "Epoch 239/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 4.7564e-06 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
      "Epoch 240/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 4.7410e-06 - accuracy: 1.0000 - val_loss: 0.0078 - val_accuracy: 0.9995\n",
      "Epoch 241/940\n",
      "36000/36000 [==============================] - 20s 547us/step - loss: 3.8654e-06 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
      "Epoch 242/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 3.4743e-06 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
      "Epoch 243/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 4.0673e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9995\n",
      "Epoch 244/940\n",
      "36000/36000 [==============================] - 19s 537us/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 0.0081 - val_accuracy: 0.9995\n",
      "Epoch 245/940\n",
      "36000/36000 [==============================] - 19s 541us/step - loss: 7.6544e-04 - accuracy: 0.9999 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
      "Epoch 246/940\n",
      "36000/36000 [==============================] - 19s 537us/step - loss: 7.1623e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 247/940\n",
      "36000/36000 [==============================] - 19s 534us/step - loss: 4.2816e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 248/940\n",
      "36000/36000 [==============================] - 19s 537us/step - loss: 7.1482e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 249/940\n",
      "36000/36000 [==============================] - 19s 533us/step - loss: 4.4212e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 250/940\n",
      "36000/36000 [==============================] - 19s 534us/step - loss: 3.8169e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 251/940\n",
      "36000/36000 [==============================] - 19s 538us/step - loss: 8.3460e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 252/940\n",
      "36000/36000 [==============================] - 20s 542us/step - loss: 4.6063e-04 - accuracy: 0.9999 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 253/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 3.0980e-04 - accuracy: 0.9998 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 254/940\n",
      "36000/36000 [==============================] - 20s 552us/step - loss: 2.7532e-04 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 255/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 7.4101e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 256/940\n",
      "36000/36000 [==============================] - 20s 542us/step - loss: 3.8317e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 257/940\n",
      "36000/36000 [==============================] - 19s 539us/step - loss: 4.5900e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 258/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 3.5486e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 259/940\n",
      "36000/36000 [==============================] - 19s 540us/step - loss: 3.2872e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 260/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 3.4249e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 261/940\n",
      "36000/36000 [==============================] - 20s 548us/step - loss: 3.0008e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 262/940\n",
      "36000/36000 [==============================] - 20s 547us/step - loss: 4.9367e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 263/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 4.3192e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 264/940\n",
      "36000/36000 [==============================] - 20s 545us/step - loss: 2.8428e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 265/940\n",
      "36000/36000 [==============================] - 20s 547us/step - loss: 2.5624e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 266/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 2.4808e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 267/940\n",
      "36000/36000 [==============================] - 20s 547us/step - loss: 2.3975e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 268/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 2.3748e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 269/940\n",
      "36000/36000 [==============================] - 20s 547us/step - loss: 2.2150e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 270/940\n",
      "36000/36000 [==============================] - 20s 549us/step - loss: 2.2604e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 271/940\n",
      "36000/36000 [==============================] - 20s 547us/step - loss: 2.0625e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 272/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 1.9589e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 273/940\n",
      "36000/36000 [==============================] - 20s 554us/step - loss: 1.9316e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 274/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 1.7909e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 275/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 1.7127e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 276/940\n",
      "36000/36000 [==============================] - 20s 549us/step - loss: 1.6608e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 277/940\n",
      "36000/36000 [==============================] - 20s 549us/step - loss: 1.5940e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 278/940\n",
      "36000/36000 [==============================] - 20s 552us/step - loss: 1.0426e-04 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 279/940\n",
      "36000/36000 [==============================] - 20s 544us/step - loss: 1.8681e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 280/940\n",
      "36000/36000 [==============================] - 20s 543us/step - loss: 2.6444e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 281/940\n",
      "36000/36000 [==============================] - 20s 549us/step - loss: 1.7233e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 282/940\n",
      "36000/36000 [==============================] - 20s 545us/step - loss: 1.5804e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 283/940\n",
      "36000/36000 [==============================] - 20s 550us/step - loss: 1.5243e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 284/940\n",
      "36000/36000 [==============================] - 20s 551us/step - loss: 1.4371e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 285/940\n",
      "36000/36000 [==============================] - 20s 545us/step - loss: 1.4667e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 286/940\n",
      "36000/36000 [==============================] - 20s 545us/step - loss: 1.4074e-05 - accuracy: 1.0000 - val_loss: 0.0075 - val_accuracy: 0.9995\n",
      "Epoch 287/940\n",
      "36000/36000 [==============================] - 20s 554us/step - loss: 1.2402e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 288/940\n",
      "36000/36000 [==============================] - 20s 545us/step - loss: 6.2080e-04 - accuracy: 0.9999 - val_loss: 0.0079 - val_accuracy: 0.9995\n",
      "Epoch 289/940\n",
      "36000/36000 [==============================] - 20s 543us/step - loss: 1.9778e-04 - accuracy: 0.9999 - val_loss: 0.0109 - val_accuracy: 0.9990\n",
      "Epoch 290/940\n",
      "36000/36000 [==============================] - 20s 548us/step - loss: 5.7130e-05 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9992\n",
      "Epoch 291/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 4.3894e-04 - accuracy: 1.0000 - val_loss: 0.0080 - val_accuracy: 0.9992\n",
      "Epoch 292/940\n",
      "36000/36000 [==============================] - 20s 546us/step - loss: 4.2775e-05 - accuracy: 1.0000 - val_loss: 0.0069 - val_accuracy: 0.9992\n",
      "Epoch 293/940\n",
      "36000/36000 [==============================] - 20s 548us/step - loss: 3.6119e-05 - accuracy: 1.0000 - val_loss: 0.0068 - val_accuracy: 0.9995\n",
      "Epoch 294/940\n",
      "36000/36000 [==============================] - 20s 544us/step - loss: 3.6837e-05 - accuracy: 1.0000 - val_loss: 0.0070 - val_accuracy: 0.9995\n",
      "Epoch 295/940\n",
      "36000/36000 [==============================] - 20s 551us/step - loss: 3.2655e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 296/940\n",
      "36000/36000 [==============================] - 20s 556us/step - loss: 3.0360e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 297/940\n",
      "36000/36000 [==============================] - 20s 552us/step - loss: 2.9614e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 298/940\n",
      "36000/36000 [==============================] - 20s 557us/step - loss: 2.9719e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 299/940\n",
      "36000/36000 [==============================] - 20s 554us/step - loss: 2.6874e-05 - accuracy: 1.0000 - val_loss: 0.0071 - val_accuracy: 0.9995\n",
      "Epoch 300/940\n",
      "36000/36000 [==============================] - 20s 552us/step - loss: 2.6129e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 301/940\n",
      "36000/36000 [==============================] - 20s 554us/step - loss: 2.5468e-05 - accuracy: 1.0000 - val_loss: 0.0072 - val_accuracy: 0.9995\n",
      "Epoch 302/940\n",
      "36000/36000 [==============================] - 20s 558us/step - loss: 2.4107e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 303/940\n",
      "36000/36000 [==============================] - 20s 555us/step - loss: 2.4127e-05 - accuracy: 1.0000 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 304/940\n",
      "36000/36000 [==============================] - 20s 559us/step - loss: 2.1723e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 305/940\n",
      "36000/36000 [==============================] - 20s 557us/step - loss: 2.0839e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 306/940\n",
      "36000/36000 [==============================] - 20s 555us/step - loss: 2.0050e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 307/940\n",
      "36000/36000 [==============================] - 20s 556us/step - loss: 2.1323e-05 - accuracy: 1.0000 - val_loss: 0.0074 - val_accuracy: 0.9995\n",
      "Epoch 308/940\n",
      "36000/36000 [==============================] - 20s 559us/step - loss: 1.8972e-05 - accuracy: 1.0000 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 309/940\n",
      "36000/36000 [==============================] - 20s 553us/step - loss: 1.8721e-05 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 0.9995\n",
      "Epoch 310/940\n",
      "36000/36000 [==============================] - 21s 597us/step - loss: 0.0017 - accuracy: 0.9997 - val_loss: 0.0082 - val_accuracy: 0.9992\n",
      "Epoch 311/940\n",
      "36000/36000 [==============================] - 21s 589us/step - loss: 9.3116e-05 - accuracy: 1.0000 - val_loss: 0.0066 - val_accuracy: 0.9992\n",
      "Epoch 312/940\n",
      "36000/36000 [==============================] - 20s 563us/step - loss: 3.9170e-04 - accuracy: 0.9999 - val_loss: 0.0076 - val_accuracy: 0.9995\n",
      "Epoch 313/940\n",
      "28160/36000 [======================>.......] - ETA: 4s - loss: 6.9670e-05 - accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-a08799dab199>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m940\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/fatemeh/anaconda3/envs/finger/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/home/fatemeh/anaconda3/envs/finger/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fatemeh/anaconda3/envs/finger/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1431\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fatemeh/anaconda3/envs/finger/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(XT[:n_train,:,:], yT[:n_train],epochs = 940, batch_size = 512, verbose = 1, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Result for: n_train  ', 40000, '  epochs:  ', 60)\n",
      "('FP: ', 0.0, 'TP: ', 0.8858636363636364, 'FN: ', 0.11413636363636363)\n",
      "('Accuracy: ', 0.9402142857142857)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(xt[0:,:,:])\n",
    "compute_performace(y_true = yt[0:], y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all features\n",
    "\n",
    "('Result for: n_train  ', 40000, '  epochs:  ', 60)\n",
    "('FP: ', 0.0, 'TP: ', 0.9161818181818182, 'FN: ', 0.08381818181818182)\n",
    "('Accuracy: ', 0.9560952380952381)\n",
    "('Result for: n_train  ', 80000, '  epochs:  ', 66)\n",
    "('FP: ', 0.0, 'TP: ', 0.9940783190066858, 'FN: ', 0.0059216809933142316)\n",
    "('Accuracy: ', 0.9969)\n",
    "('Result for: n_train  ', 40000, '  epochs:  ', 60+312)\n",
    "('FP: ', 0.0, 'TP: ', 0.8858636363636364, 'FN: ', 0.11413636363636363)\n",
    "('Accuracy: ', 0.9402142857142857)\n",
    "##############REDDDDDDDDDDDD with 60 features\n",
    "('Result for: n_train  ', 40000, '  epochs:  ', 500)\n",
    "('FP: ', 0.04407135362014691, 'TP: ', 0.9153772683858644, 'FN: ', 0.08462273161413562)\n",
    "('Accuracy: ', 0.9347)\n",
    "('Result for: n_train  ', 40000, '  epochs:  ', 1000)\n",
    "('FP: ', 0.02329485834207765, 'TP: ', 0.9186246418338109, 'FN: ', 0.08137535816618911)\n",
    "('Accuracy: ', 0.9463)\n",
    "\n",
    "('Result for: n_train  ', 80000, '  epochs:  ', 500)\n",
    "('FP: ', 0.06841552990556138, 'TP: ', 0.9698185291308501, 'FN: ', 0.030181470869149952)\n",
    "('Accuracy: ', 0.9516)\n",
    "\n",
    "('Result for: n_train  ', 80000, '  epochs:  ', 1000)\n",
    "('FP: ', 0.033578174186778595, 'TP: ', 0.9749761222540592, 'FN: ', 0.025023877745940785)\n",
    "('Accuracy: ', 0.9709)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Result for: n_train  ', 10000, '  epochs:  ', 200)\n",
      "('FP: ', 0.0, 'TP: ', 1.0, 'FN: ', 0.0)\n",
      "('Accuracy: ', 1.0)\n"
     ]
    }
   ],
   "source": [
    "############  check if model overfits with small train data  #########\n",
    "y_pred = model.predict(XT[:n_train])\n",
    "compute_performace(y_true = yT[:n_train], y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_performace(y_true, y_pred):\n",
    "    #yT = yTest\n",
    "    y_pred_proc = y_pred_process(y_pred, 0.5)\n",
    "    accur = 0\n",
    "    true_pos = 0\n",
    "    false_pos = 0\n",
    "    number_of_all_one = sum(y_true)\n",
    "    nZeros = len(y_true) - number_of_all_one\n",
    "    false_neg = 0\n",
    "    for v in range(len(y_pred)):\n",
    "        if y_true[v] == 1 and y_pred_proc[v] == 1:\n",
    "            accur += 1\n",
    "            true_pos += 1\n",
    "        if y_pred_proc[v] == 0 and y_true[v] == 0:\n",
    "             accur += 1\n",
    "        if y_pred_proc[v] == 1 and y_true[v] == 0:\n",
    "            false_pos += 1\n",
    "        if y_pred_proc[v] == 0 and y_true[v] == 1:\n",
    "            false_neg += 1\n",
    "\n",
    "\n",
    "    print(\"Result for: n_train  \", n_train, \"  epochs:  \", epochs)\n",
    "    print(\"FP: \", false_pos/float(nZeros),\"TP: \", true_pos/float(number_of_all_one),\"FN: \" ,false_neg/float(number_of_all_one))\n",
    "    accur /= float(len(y_pred))\n",
    "    print(\"Accuracy: \", accur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Result for: n_train  ', 5000, '  epochs:  ', 100)\n",
      "('FP: ', 1.0, 'TP: ', 1.0, 'FN: ', 0.0)\n",
      "('Accuracy: ', 0.5384615384615384)\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(xTest2)\n",
    "compute_performace(y_true = yTest, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Result for: n_train  ', 5000, '  epochs:  ', 200)\n",
      "('FP: ', 0.0, 'TP: ', 1.0, 'FN: ', 0.0)\n",
      "('Accuracy: ', 1.0)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################### feature selection: 21 April 2020\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif, f_regression\n",
    "\n",
    "test = SelectKBest(score_func = f_regression, k=100)\n",
    "fit = test.fit(XTrain, yTrain)\n",
    "features = fit.transform(XTrain)\n",
    "train_features = np.expand_dims(features, axis=1)\n",
    "\n",
    "features_t = train_features[order]\n",
    "y_t  = yTrain[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "\n",
    "def write_to_json(model, number):\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model_vlm_0remove_2_\" + str(number) + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"model_vlm_0remove_2_\" + str(number) + \".h5\")\n",
    "\n",
    "print(len(XTrainCopy),len(xTestCopy))# 30\n",
    "scaler = MinMaxScaler(feature_range = (0, 1))\n",
    "xT, yT = buildSmallerTrainDataSameFalseandTrue(xTestCopy, yTestCopy, size = 10000)\n",
    "xT = scaler.fit_transform(xT)\n",
    "xT = np.expand_dims(xT, axis=1)\n",
    "\n",
    "X, y = buildSmallerTrainDataSameFalseandTrue(XTrainCopy, yTrainCopy, size = 110000)\n",
    "print(\"finished reading dataset\")\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X = np.expand_dims(X, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_encoder_by_slice(p, model_name):\n",
    "    chunk = 10\n",
    "    Input_ipd = Input(shape=(chunk, 1), name='input1')  # this is needed just for the decoding\n",
    "    \n",
    "    Input_key = Input(shape=(key_length,), name='input2')\n",
    "    fingerprint_mult = Input(shape=(chunk,), name='input3')\n",
    "    fingerprint_sub = Input(shape=(chunk,), name='input4')\n",
    "    \n",
    "    ipd = Flatten()(Input_ipd)\n",
    "    key1 = Dense(32, name='key1')(Input_key)\n",
    "    if p != 0:\n",
    "        Input_ipd_pre = Input(shape=(chunk, ), name='ipd_delay' + str(p-1))\n",
    "#         Input_ipd_pre = Flatten()(Input_ipd_pre)\n",
    "        sliced_ipd = Concatenate(name = 'concat'+ str(p))([Input_ipd_pre, ipd])\n",
    "    else:\n",
    "        sliced_ipd = Concatenate(name = 'concat'+ str(p))([ipd, ipd])\n",
    "        \n",
    "    ipd1 = Dense(32, name = 'dense'+ str(p))(sliced_ipd)\n",
    "    batch_2 = BatchNormalization(name = 'batch'+ str(p))(ipd1)\n",
    "    relu_2 = Activation('relu', name = 'act'+ str(p))(batch_2)\n",
    "\n",
    "    ipds_merged_all = Concatenate(name = 'concat_key_'+ str(p))([relu_2, key1])\n",
    "    dense_enc1 = Dense(64, name = 'dense_enc1' + str(p))(ipds_merged_all)\n",
    "    batch_2 = BatchNormalization(name = 'batch2_'+ str(p))(dense_enc1)\n",
    "    relu_2 = Activation('relu', name = 'act2_'+ str(p))(batch_2)\n",
    "    dense_drop_enc1 = Dropout(0.3, name = 'dense_drop_enc1' + str(p))(relu_2)\n",
    "        \n",
    "    x_fingerprint_sig = Dense(chunk, name = 'fingerprint_sig' + str(p), activation = 'sigmoid')(dense_drop_enc1)\n",
    "    x_fingerprint_mult = Multiply(name = 'fingerprint_mult')([x_fingerprint_sig, fingerprint_mult])\n",
    "    x_fingerprint = Add(name = 'ipd_delay')([x_fingerprint_mult, fingerprint_sub])\n",
    "    \n",
    "\n",
    "    x_fingerprint = Reshape((chunk, 1), name='fingerprint')(x_fingerprint)\n",
    "    if p !=0:\n",
    "        \n",
    "        encoder_ins = [ Input_key, Input_ipd_pre, Input_ipd, fingerprint_mult, fingerprint_sub]\n",
    "        model_encoder = Model(inputs = encoder_ins, outputs = [x_fingerprint])\n",
    "    else:\n",
    "        encoder_ins = [ Input_key, Input_ipd, fingerprint_mult, fingerprint_sub]\n",
    "        model_encoder = Model(inputs = encoder_ins, outputs = [x_fingerprint])\n",
    "        \n",
    "    model_encoder.load_weights(filepath = path + model_name + \".h5\", by_name=True)\n",
    "    return model_encoder\n",
    "  \n",
    "def load_decoder(key_length, sample_size, model_name):\n",
    "    Input_ipd = Input(shape=(sample_size, 1), name='input1') \n",
    "    \n",
    "    cconv_dec_2 = Conv1D(filters = 20, kernel_size=10, padding='same', name='conv_dec_2')(Input_ipd)\n",
    "    conv_batch_2 = BatchNormalization(name='conv_batch_2')(conv_dec_2)\n",
    "    conv_relu_2 = Activation('relu', name='conv_relu_2')(conv_batch_2)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_2')(conv_relu_2)\n",
    "    max_pool_dec_2 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_2\")(conv_drop_2)\n",
    "    \n",
    "    conv_dec_3 = Conv1D(filters = 10, kernel_size=10, padding='same', name='conv_dec_3')(max_pool_dec_2)\n",
    "    conv_batch_3 = BatchNormalization(name='conv_batch_3')(conv_dec_3)\n",
    "    conv_relu_3 = Activation('relu', name='conv_relu_3')(conv_batch_3)\n",
    "    conv_drop_2 = Dropout(0.3, name='conv_drop_3')(conv_relu_3)\n",
    "    max_pool_dec_3 = MaxPooling1D(pool_size=1, name=\"max_pool_dec_3\")(conv_drop_2)\n",
    "    max_pool_dec_3_f = Flatten(name =\"flate_max3\")(max_pool_dec_3)\n",
    "\n",
    "    dense_dec_1 = Dense(256, name='dense_dec_1')(max_pool_dec_3_f)\n",
    "    dense_batch_dec1 = BatchNormalization(name='dense_batch_dec1')(dense_dec_1)\n",
    "    dense_relu_dec1 = Activation('relu', name='dense_relu_dec1')(dense_batch_dec1)\n",
    "    dense_drop_dec1 = Dropout(0.3, name='dense_drop_dec1')(dense_relu_dec1)    \n",
    "    \n",
    "    dense_dec_2 = Dense(64, name='dense_dec_2')(dense_drop_dec1)\n",
    "    dense_batch_dec2 = BatchNormalization(name='dense_batch_dec2')(dense_dec_2)\n",
    "    dense_relu_dec2 = Activation('relu', name='dense_relu_dec2')(dense_batch_dec2)\n",
    "    dense_drop_dec2 = Dropout(0.3, name='dense_drop_dec2')(dense_relu_dec2)\n",
    "    \n",
    "    key_hat = Dense(key_length, activation='softmax', name='key_hat')(dense_drop_dec2)\n",
    "    \n",
    "    \n",
    "    model_decoder = Model(inputs=[Input_ipd], outputs=[key_hat])\n",
    "    model_decoder.load_weights(filepath=path + model_name + \".h5\", by_name=True)\n",
    "\n",
    "    return model_decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_Dense_NN_model():\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Flatten(input_shape=(1, 60)))\n",
    "      \n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1, activation='sigmoid'))#it was sigmoid before: jan 21, 2019\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_RR_NN_model():\n",
    "    model = Sequential()    \n",
    "    model.add(LSTM(256,input_shape=(1, 600)))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    \n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = fit.transform(xTest)\n",
    "test_features = np.expand_dims(test_features, axis=1)\n",
    "y_pred = model2.predict(test_features)\n",
    "compute_performace(y_true = yTest, y_pred =y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = buildSmallerTrainDataSameFalseandTrue(XTrainCopy, yTrainCopy, size = 500)\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "X = np.expand_dims(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer is not a legal parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-682d0497f0bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%f (%f) with: %r\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mgridSearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-682d0497f0bf>\u001b[0m in \u001b[0;36mgridSearch\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     ]\n\u001b[1;32m     30\u001b[0m     \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuned_parameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;31m# summarize results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best: %f using %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrid_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0mtrain_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparameters\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mset_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m         \"\"\"\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msk_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mcheck_params\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mparams_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'nb_epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                     raise ValueError(\n\u001b[0;32m---> 90\u001b[0;31m                         '{} is not a legal parameter'.format(params_name))\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer is not a legal parameter"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def gridSearch():\n",
    "    seed = 7\n",
    "    np.random.seed(seed)\n",
    "    # load pima indians dataset\n",
    "    # create model\n",
    "    model = get_Dense_NN_model()\n",
    "\n",
    "    model = KerasClassifier(build_fn=model, epochs=150,verbose=1)\n",
    "    \n",
    "    # grid search epochs, batch size and optimizer\n",
    "    optimizers = ['rmsprop', 'adam']\n",
    "#     init = ['glorot_uniform', 'normal', 'uniform']\n",
    "    epochs = [50, 100, 150]\n",
    "    batches = [5, 10, 20]\n",
    "    param_grid = dict(optimizer=optimizers, epochs=epochs, batch_size=batches)\n",
    "    \n",
    "    tuned_parameters = [\n",
    "        {'optimizer': ['adam'], 'batch_size': [5, 10, 20],\n",
    "         'epoch': [50, 100, 200]}\n",
    "       \n",
    "\n",
    "    ]\n",
    "    grid = GridSearchCV(estimator=model, param_grid=tuned_parameters, cv=5)\n",
    "    grid_result = grid.fit(X, y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "        \n",
    "gridSearch()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
