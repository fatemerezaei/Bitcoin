{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy.spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "\n",
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def convert_stringArrays_to_floatArray(array):\n",
    "    intArray = []\n",
    "\n",
    "    for k in array:\n",
    "        if isfloat(k):\n",
    "            intArray.append(float(k))\n",
    "    return intArray\n",
    "\n",
    "\n",
    "def convert_stringArrays_to_intArray(array):\n",
    "    intArray = []\n",
    "\n",
    "    for k in array:\n",
    "        if isfloat(k):\n",
    "            intArray.append(int(k))\n",
    "    return intArray\n",
    "\n",
    "\n",
    "def readFromFile(path):\n",
    "    with open(path, 'r') as content_file:\n",
    "        content = content_file.read()\n",
    "        return content  # .split(\" \")\n",
    "\n",
    "\n",
    "def createHistFromPkst(pkts):\n",
    "    numberOfPkts = 1\n",
    "\n",
    "    hist = [0] * 1515\n",
    "    largerThanMTU = 0\n",
    "    for i in range(0, len(pkts)):\n",
    "        if pkts[i] not in [0, 40, 52]:\n",
    "            if pkts[i] < len(hist):\n",
    "                hist[int(pkts[i])] += 1\n",
    "                numberOfPkts += 1\n",
    "            else:\n",
    "                largerThanMTU += 1\n",
    "\n",
    "    for h in range(0, len(hist)):\n",
    "        hist[h] /= float(numberOfPkts)\n",
    "    if largerThanMTU / float((largerThanMTU + numberOfPkts)) < 0.05:\n",
    "        return hist\n",
    "    else:\n",
    "        return \"error\"\n",
    "\n",
    "\n",
    "def plot_features(X, y, labels):\n",
    "    # from sklearn.datasets.samples_generator import make_blobs\n",
    "    # X, y = make_blobs(n_samples=50, centers=3, n_features=5, random_state=0)\n",
    "    X_norm = (X - X.min()) / (X.max() - X.min())\n",
    "\n",
    "    pca = sklearnPCA(n_components=2)  # 2-dimensional PCA\n",
    "    XPCA = pca.fit_transform(X_norm)\n",
    "    transformed = pd.DataFrame(pca.fit_transform(X_norm))\n",
    "    colors = [\"red\", \"blue\", \"yellow\", \"pink\", \"lightgreen\"]\n",
    "    for k in range(len(labels)):\n",
    "        plt.scatter(transformed[y == k][0], transformed[y == k][1], label=labels[k], c=colors[k], edgecolors=colors[k])\n",
    "        # plt.scatter(XPCA[:, 0][100 * k:100 * (1 + k)],\n",
    "        #       XPCA[:, 1][100 * k:100 * (1 + k)], label=labels[k], c=colors[k],\n",
    "        #        edgecolors=colors[k])\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "def computerAccuracy(clf, otherTest, bitcoin_test):\n",
    "    accuracy = 0\n",
    "    for k in range(0, len(otherTest)):\n",
    "        if clf.predict(np.array(otherTest[k]).reshape(1, -1))[0] in [0, 2, 3, 4]:\n",
    "            accuracy += 1\n",
    "    for k in range(0, len(bitcoin_test)):\n",
    "        if k%10==0:\n",
    "            print\n",
    "        print clf.predict(np.array(bitcoin_test[k]).reshape(1, -1))[0],\n",
    "        if clf.predict(np.array(bitcoin_test[k]).reshape(1, -1))[0] == 1:\n",
    "            \n",
    "            accuracy += 1\n",
    "\n",
    "    # plotMax(maxOther, maxBitcoin)\n",
    "    return accuracy / float(len(otherTest) + len(bitcoin_test))\n",
    "\n",
    "def computeRecall(clf, bitcoin_test):\n",
    "    truePos = 0\n",
    "    for k in range(0, len(bitcoin_test)):\n",
    "        if clf.predict(np.array(bitcoin_test[k]).reshape(1, -1))[0] == 1:\n",
    "            truePos += 1\n",
    "    return truePos / float(len(bitcoin_test))\n",
    "\n",
    "def computePrecision(clf, otherTest, bitcoin_test):\n",
    "    truePostive = 0\n",
    "    falsePositive = 0\n",
    "    for k in bitcoin_test:\n",
    "        if clf.predict(np.array(k).reshape(1, -1))[0] == 1:\n",
    "            truePostive += 1\n",
    "\n",
    "    for k in otherTest:\n",
    "        if clf.predict(np.array(k).reshape(1, -1))[0] == 1:\n",
    "            falsePositive += 1\n",
    "    precsion = truePostive / float(falsePositive + truePostive)\n",
    "    return precsion\n",
    "\n",
    "\n",
    "def normalzieVector(X):\n",
    "    X_norm = []\n",
    "    for x in X:\n",
    "        temp = preprocessing.normalize(x.reshape(-1, 1))\n",
    "        X_norm.extend(temp.reshape(1, -1))\n",
    "    return X_norm\n",
    "\n",
    "def readCombinedFeature(directory):\n",
    "    dataset = []\n",
    "    files = os.listdir(directory)\n",
    "    for f in files:\n",
    "        path = directory + f\n",
    "        sample = convert_stringArrays_to_floatArray(readFromFile(path).split(\" \"))\n",
    "        if len(sample) < 1500:\n",
    "            print path\n",
    "            continue\n",
    "        dataset.append(np.array(sample))\n",
    "    return np.array(dataset)\n",
    "\n",
    "\n",
    "def readPacketHist(path):\n",
    "    files = os.listdir(path)[0:800]\n",
    "    X_data = []\n",
    "    for f in files:\n",
    "        packets = readFromFile(path + f).split(\" \")\n",
    "        pkts = convert_stringArrays_to_floatArray(packets)\n",
    "        hist = createHistFromPkst(pkts)\n",
    "        if hist != \"error\":\n",
    "            X_data.append(np.array(hist))\n",
    "\n",
    "    return X_data\n",
    "\n",
    "def buil_db(array, value):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    n = len(array)\n",
    "    for i in range(0, n):\n",
    "        data_X.append(array[i])\n",
    "        data_Y.append(value)\n",
    "\n",
    "    return data_X, data_Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def svm_feature_names(numberOfTraining, dataset_all, names):\n",
    "    labels = []\n",
    "    X = []\n",
    "    y = []\n",
    "    other_test = []\n",
    "    bitcoin_test = []\n",
    "    vals = [0,1,0,0]\n",
    "    for i in range(0, len(names)):\n",
    "        http_x, http_y = buil_db(array=dataset_all[i][100:numberOfTraining + 100], value=vals[i])\n",
    "        X.extend(http_x)\n",
    "        y.extend(http_y)\n",
    "        labels.append(names[i])\n",
    "        if names[i]!='bitcoin':\n",
    "            other_test.extend(dataset_all[i][0:100])\n",
    "    y = np.array(y)\n",
    "    X = np.array(X)\n",
    "    X_norm = normalzieVector(X)\n",
    "    \n",
    "    other_test_norm = normalzieVector(other_test)\n",
    "    # plot_features(X, y, labels)  # Plot the features to see if they are\n",
    "    clf = RandomForestClassifier(max_depth=100, n_estimators=100,\n",
    "                                 random_state=0)  # SVC(kernel='linear', C=1)  # svm.nuVC\n",
    "    clf.fit(X_norm, y)\n",
    "\n",
    "    return clf, other_test_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http\n",
      "bitcoin\n",
      "bittorent\n",
      "voip\n"
     ]
    }
   ],
   "source": [
    "dataset_all = []\n",
    "names = ['http', 'bitcoin', \"bittorent\", \"voip\"]\n",
    "for n in names:\n",
    "    print n\n",
    "    dataset = readPacketHist(path='/home/fatemeh/Bitcoin/nov 13/hist/' + n + \"/\")\n",
    "    # readCombinedFeature(directory='/home/fatemeh/Bitcoin/combined/' + n + \"/features/\")\n",
    "    dataset_all.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "clf, otherTest= svm_feature_names(numberOfTraining=n, dataset_all=dataset_all, names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = readPacketHist(path='/home/fatemeh/Bitcoin/nov 13/hist/noisyBitcoin/')#noisyBitMultipleTab/2/\n",
    "bitcoin_test=data[0:100]\n",
    "bitcoin_test= normalzieVector(bitcoin_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = computerAccuracy(clf, otherTest, bitcoin_test)\n",
    "recall = computeRecall(clf, bitcoin_test)\n",
    "precision = computePrecision(clf, otherTest, bitcoin_test)\n",
    "print \"F1\",accuracy, recall, precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
